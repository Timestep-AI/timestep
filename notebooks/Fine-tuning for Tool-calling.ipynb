{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning for Tool-calling\n",
    "\n",
    "This example was copied and modified from https://github.com/openai/openai-cookbook/blob/main/examples/Fine_tuning_for_function_calling.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import base64\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "# import pandas as pd\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from typing import Any, Dict, List, Generator\n",
    "\n",
    "from timestep.config import settings\n",
    "\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\", settings.openai_api_key),\n",
    "    base_url=os.getenv(\"OPENAI_BASE_URL\", settings.openai_base_url),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook covers how to fine-tune to increase function calling accuracy and reliability. You can find more information on function calling [here](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_call_functions_with_chat_models.ipynb), and on fine tuning [here](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For context, from the function calling notebook above:\n",
    "\n",
    "> `tools` is an optional parameter in the Chat Completion API which can be used to provide function specifications. The purpose of this is to enable models to generate function arguments which adhere to the provided specifications. Note that the API will not actually execute any function calls. It is up to developers to execute function calls using model outputs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function calling is a very powerful tool when it functions as intended. However, we have seen that as the number of functions increases, and the complexity of the task at hand increases, function calling becomes less accurate (e.g.: more hallucinated invocations, and incorrect invocations).\n",
    "\n",
    "Before fine tuning for function calling, it's best to begin with:\n",
    "\n",
    "- Improvements to the function definitions. Make them more clear, and more distinct from one another.\n",
    "- Experiment with prompt engineering: often a more detailed prompt can help the model call the correct function.\n",
    "\n",
    "_If_ the steps above fail to improve function calling to a satisfactory level, then you can try fine tuning for function calling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains three sections\n",
    "\n",
    "- **Assessing baseline function calling performance:** Evaluating an out-of-the-box `gpt-3.5-turbo` model on our given function (let's assume that for latency + cost reasons we cannot use `gpt-4o` for a drone copilot)\n",
    "- **Generating synthetic data:** Using `gpt-4o` to create 'golden' set of prompts and function invocations to use as training data\n",
    "- **Fine-tuning**: Running the fine tuning job, and evaluating the fine-tuned model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: _This notebook provides an example of how to create synthetic training data for fine tuning for function calling given just a list of functions. While real-world production test evals are preferable, this method produces strong results and can be used in conjunction with real-world training data._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting baseline function calling performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define utility functions for making calls to the Chat Completions API, one to get the completion and one to get the function call.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_completion(\n",
    "    messages: list[dict[str, str]],\n",
    "    model: str = \"gpt-3.5-turbo\",\n",
    "    max_tokens=500,\n",
    "    temperature=0.0,\n",
    "    stop=None,\n",
    "    tools=None,\n",
    "    seed=42,\n",
    "    functions=None,\n",
    "    tool_choice=None,\n",
    ") -> str:\n",
    "    params = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": temperature,\n",
    "        \"stop\": stop,\n",
    "        \"tools\": tools,\n",
    "        \"seed\": seed,\n",
    "        \"tool_choice\": tool_choice,\n",
    "    }\n",
    "    if functions:\n",
    "        params[\"functions\"] = functions\n",
    "\n",
    "    print(f'params: {params}')\n",
    "\n",
    "    completion = client.chat.completions.create(**params)\n",
    "    return completion.choices[0].message, completion.usage\n",
    "\n",
    "\n",
    "def eval(model: str, system_prompt: str, function_list, prompts_to_expected_tool_name):\n",
    "    \"\"\"\n",
    "    Evaluate the performance of a model in selecting the correct function based on given prompts.\n",
    "\n",
    "    Args:\n",
    "        model (str): The name of the model to be evaluated.\n",
    "        system_prompt (str): The system prompt to be used in the chat completion.\n",
    "        function_list (list): A list of functions that the model can call.\n",
    "        prompts_to_expected_tool_name (dict): A dictionary mapping prompts to their expected function names.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    prompts_to_actual = []\n",
    "    latencies = []\n",
    "    tokens_used = []\n",
    "\n",
    "    for prompt, expected_function in prompts_to_expected_tool_name.items():\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ]\n",
    "\n",
    "        start_time = time.time()\n",
    "        completion, usage = get_chat_completion(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            seed=42,\n",
    "            tools=function_list,\n",
    "            temperature=0.0,\n",
    "            tool_choice=\"required\",\n",
    "        )\n",
    "        end_time = time.time()\n",
    "\n",
    "        latency = (end_time - start_time) * 1000  # convert to milliseconds\n",
    "        latencies.append(latency)\n",
    "\n",
    "        prompts_to_actual.append(\n",
    "            {prompt: completion.tool_calls[0].function.name})\n",
    "\n",
    "        # Calculate tokens used\n",
    "        tokens_used.append(usage.total_tokens)\n",
    "\n",
    "    total_prompts = len(prompts_to_expected_tool_name)\n",
    "\n",
    "    # Calculate the number of matches\n",
    "    matches = sum(\n",
    "        1\n",
    "        for result in prompts_to_actual\n",
    "        if list(result.values())[0]\n",
    "        == prompts_to_expected_tool_name[list(result.keys())[0]]\n",
    "    )\n",
    "    match_percentage = (matches / total_prompts) * 100\n",
    "\n",
    "    # Calculate average latency\n",
    "    avg_latency = sum(latencies) / total_prompts\n",
    "    # Calculate average tokens used\n",
    "    avg_tokens_used = sum(tokens_used) / total_prompts\n",
    "\n",
    "    # Create a DataFrame to store the results\n",
    "    results_df = pd.DataFrame(columns=[\"Prompt\", \"Expected\", \"Match\"])\n",
    "\n",
    "    results_list = []\n",
    "    for result in prompts_to_actual:\n",
    "        prompt = list(result.keys())[0]\n",
    "        actual_function = list(result.values())[0]\n",
    "        expected_function = prompts_to_expected_tool_name[prompt]\n",
    "        match = actual_function == expected_function\n",
    "        results_list.append(\n",
    "            {\n",
    "                \"Prompt\": prompt,\n",
    "                \"Actual\": actual_function,\n",
    "                \"Expected\": expected_function,\n",
    "                \"Match\": \"Yes\" if match else \"No\",\n",
    "            }\n",
    "        )\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "\n",
    "    def style_rows(row):\n",
    "        match = row[\"Match\"]\n",
    "        background_color = \"red\" if match == \"No\" else \"white\"\n",
    "        return [\"background-color: {}; color: black\".format(background_color)] * len(\n",
    "            row\n",
    "        )\n",
    "\n",
    "    styled_results_df = results_df.style.apply(style_rows, axis=1)\n",
    "\n",
    "    # Display the DataFrame as a table\n",
    "    display(styled_results_df)\n",
    "\n",
    "    print(\n",
    "        f\"Number of matches: {matches} out of {total_prompts} ({match_percentage:.2f}%)\"\n",
    "    )\n",
    "    print(f\"Average latency per request: {avg_latency:.2f} ms\")\n",
    "    print(f\"Average tokens used per request: {avg_tokens_used:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build an intelligent drone co-pilot. We want to be able to give the co-pilot commands, and have it either call the function\n",
    "for that command, or deny that request if the command is unfeasible.\n",
    "We can first define a system prompt for the copilot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DRONE_SYSTEM_PROMPT = \"\"\"You are an intelligent AI that controls a drone. Given a command or request from the user,\n",
    "call one of your functions to complete the request. If the request cannot be completed by your available functions, call the reject_request function.\n",
    "If the request is ambiguous or unclear, reject the request.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define functions for all of the actions the copilot can take.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_list = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"takeoff_drone\",\n",
    "            \"description\": \"Initiate the drone's takeoff sequence.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"altitude\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"Specifies the altitude in meters to which the drone should ascend.\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"altitude\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"land_drone\",\n",
    "            \"description\": \"Land the drone at its current location or a specified landing point.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"current\", \"home_base\", \"custom\"],\n",
    "                        \"description\": \"Specifies the landing location for the drone.\",\n",
    "                    },\n",
    "                    \"coordinates\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"description\": \"GPS coordinates for custom landing location. Required if location is 'custom'.\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"control_drone_movement\",\n",
    "            \"description\": \"Direct the drone's movement in a specific direction.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"direction\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"forward\", \"backward\", \"left\", \"right\", \"up\", \"down\"],\n",
    "                        \"description\": \"Direction in which the drone should move.\",\n",
    "                    },\n",
    "                    \"distance\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"Distance in meters the drone should travel in the specified direction.\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"direction\", \"distance\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"set_drone_speed\",\n",
    "            \"description\": \"Adjust the speed of the drone.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"speed\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"Specifies the speed in km/h. Valid range is 0 to 100.\",\n",
    "                        \"minimum\": 0,\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"speed\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"control_camera\",\n",
    "            \"description\": \"Control the drone's camera to capture images or videos.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"mode\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"photo\", \"video\", \"panorama\"],\n",
    "                        \"description\": \"Camera mode to capture content.\",\n",
    "                    },\n",
    "                    \"duration\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"Duration in seconds for video capture. Required if mode is 'video'.\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"mode\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"control_gimbal\",\n",
    "            \"description\": \"Adjust the drone's gimbal for camera stabilization and direction.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"tilt\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"Tilt angle for the gimbal in degrees.\",\n",
    "                    },\n",
    "                    \"pan\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"Pan angle for the gimbal in degrees.\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"tilt\", \"pan\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"set_drone_lighting\",\n",
    "            \"description\": \"Control the drone's lighting for visibility and signaling.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"mode\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"on\", \"off\", \"blink\", \"sos\"],\n",
    "                        \"description\": \"Lighting mode for the drone.\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"mode\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"return_to_home\",\n",
    "            \"description\": \"Command the drone to return to its home or launch location.\",\n",
    "            \"parameters\": {\"type\": \"object\", \"properties\": {}},\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"set_battery_saver_mode\",\n",
    "            \"description\": \"Toggle battery saver mode.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"status\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"on\", \"off\"],\n",
    "                        \"description\": \"Toggle battery saver mode.\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"status\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"set_obstacle_avoidance\",\n",
    "            \"description\": \"Configure obstacle avoidance settings.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"mode\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"on\", \"off\"],\n",
    "                        \"description\": \"Toggle obstacle avoidance.\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"mode\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"set_follow_me_mode\",\n",
    "            \"description\": \"Enable or disable 'follow me' mode.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"status\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"on\", \"off\"],\n",
    "                        \"description\": \"Toggle 'follow me' mode.\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"status\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"calibrate_sensors\",\n",
    "            \"description\": \"Initiate calibration sequence for drone's sensors.\",\n",
    "            \"parameters\": {\"type\": \"object\", \"properties\": {}},\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"set_autopilot\",\n",
    "            \"description\": \"Enable or disable autopilot mode.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"status\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"on\", \"off\"],\n",
    "                        \"description\": \"Toggle autopilot mode.\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"status\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"configure_led_display\",\n",
    "            \"description\": \"Configure the drone's LED display pattern and colors.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"pattern\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"solid\", \"blink\", \"pulse\", \"rainbow\"],\n",
    "                        \"description\": \"Pattern for the LED display.\",\n",
    "                    },\n",
    "                    \"color\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"red\", \"blue\", \"green\", \"yellow\", \"white\"],\n",
    "                        \"description\": \"Color for the LED display. Not required if pattern is 'rainbow'.\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"pattern\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"set_home_location\",\n",
    "            \"description\": \"Set or change the home location for the drone.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"coordinates\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"description\": \"GPS coordinates for the home location.\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"coordinates\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"reject_request\",\n",
    "            \"description\": \"Use this function if the request is not possible.\",\n",
    "            \"parameters\": {\"type\": \"object\", \"properties\": {}},\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For starters, let's see how function calling performs with some straight forward feasible prompts, and then couple of obviously impossible requests which call the 'reject_request' function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "straightforward_prompts_to_expected = {\n",
    "    \"Land the drone at the home base\": \"land_drone\",\n",
    "    \"Take off the drone to 50 meters\": \"takeoff_drone\",\n",
    "    \"Change speed to 15 kilometers per hour\": \"set_drone_speed\",\n",
    "    \"Turn into an elephant!\": \"reject_request\",\n",
    "    \"Move the drone forward by 10 meters\": \"control_drone_movement\",\n",
    "    \"I want the LED display to blink in red\": \"configure_led_display\",\n",
    "    \"Can you take a photo?\": \"control_camera\",\n",
    "    \"Can you detect obstacles?\": \"set_obstacle_avoidance\",\n",
    "    \"Can you dance for me?\": \"reject_request\",\n",
    "    \"Can you follow me?\": \"set_follow_me_mode\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'model': 'gpt-3.5-turbo', 'messages': [{'role': 'system', 'content': 'You are an intelligent AI that controls a drone. Given a command or request from the user,\\ncall one of your functions to complete the request. If the request cannot be completed by your available functions, call the reject_request function.\\nIf the request is ambiguous or unclear, reject the request.'}, {'role': 'user', 'content': 'Land the drone at the home base'}], 'max_tokens': 500, 'temperature': 0.0, 'stop': None, 'tools': [{'type': 'function', 'function': {'name': 'takeoff_drone', 'description': \"Initiate the drone's takeoff sequence.\", 'parameters': {'type': 'object', 'properties': {'altitude': {'type': 'integer', 'description': 'Specifies the altitude in meters to which the drone should ascend.'}}, 'required': ['altitude']}}}, {'type': 'function', 'function': {'name': 'land_drone', 'description': 'Land the drone at its current location or a specified landing point.', 'parameters': {'type': 'object', 'properties': {'location': {'type': 'string', 'enum': ['current', 'home_base', 'custom'], 'description': 'Specifies the landing location for the drone.'}, 'coordinates': {'type': 'object', 'description': \"GPS coordinates for custom landing location. Required if location is 'custom'.\"}}, 'required': ['location']}}}, {'type': 'function', 'function': {'name': 'control_drone_movement', 'description': \"Direct the drone's movement in a specific direction.\", 'parameters': {'type': 'object', 'properties': {'direction': {'type': 'string', 'enum': ['forward', 'backward', 'left', 'right', 'up', 'down'], 'description': 'Direction in which the drone should move.'}, 'distance': {'type': 'integer', 'description': 'Distance in meters the drone should travel in the specified direction.'}}, 'required': ['direction', 'distance']}}}, {'type': 'function', 'function': {'name': 'set_drone_speed', 'description': 'Adjust the speed of the drone.', 'parameters': {'type': 'object', 'properties': {'speed': {'type': 'integer', 'description': 'Specifies the speed in km/h. Valid range is 0 to 100.', 'minimum': 0}}, 'required': ['speed']}}}, {'type': 'function', 'function': {'name': 'control_camera', 'description': \"Control the drone's camera to capture images or videos.\", 'parameters': {'type': 'object', 'properties': {'mode': {'type': 'string', 'enum': ['photo', 'video', 'panorama'], 'description': 'Camera mode to capture content.'}, 'duration': {'type': 'integer', 'description': \"Duration in seconds for video capture. Required if mode is 'video'.\"}}, 'required': ['mode']}}}, {'type': 'function', 'function': {'name': 'control_gimbal', 'description': \"Adjust the drone's gimbal for camera stabilization and direction.\", 'parameters': {'type': 'object', 'properties': {'tilt': {'type': 'integer', 'description': 'Tilt angle for the gimbal in degrees.'}, 'pan': {'type': 'integer', 'description': 'Pan angle for the gimbal in degrees.'}}, 'required': ['tilt', 'pan']}}}, {'type': 'function', 'function': {'name': 'set_drone_lighting', 'description': \"Control the drone's lighting for visibility and signaling.\", 'parameters': {'type': 'object', 'properties': {'mode': {'type': 'string', 'enum': ['on', 'off', 'blink', 'sos'], 'description': 'Lighting mode for the drone.'}}, 'required': ['mode']}}}, {'type': 'function', 'function': {'name': 'return_to_home', 'description': 'Command the drone to return to its home or launch location.', 'parameters': {'type': 'object', 'properties': {}}}}, {'type': 'function', 'function': {'name': 'set_battery_saver_mode', 'description': 'Toggle battery saver mode.', 'parameters': {'type': 'object', 'properties': {'status': {'type': 'string', 'enum': ['on', 'off'], 'description': 'Toggle battery saver mode.'}}, 'required': ['status']}}}, {'type': 'function', 'function': {'name': 'set_obstacle_avoidance', 'description': 'Configure obstacle avoidance settings.', 'parameters': {'type': 'object', 'properties': {'mode': {'type': 'string', 'enum': ['on', 'off'], 'description': 'Toggle obstacle avoidance.'}}, 'required': ['mode']}}}, {'type': 'function', 'function': {'name': 'set_follow_me_mode', 'description': \"Enable or disable 'follow me' mode.\", 'parameters': {'type': 'object', 'properties': {'status': {'type': 'string', 'enum': ['on', 'off'], 'description': \"Toggle 'follow me' mode.\"}}, 'required': ['status']}}}, {'type': 'function', 'function': {'name': 'calibrate_sensors', 'description': \"Initiate calibration sequence for drone's sensors.\", 'parameters': {'type': 'object', 'properties': {}}}}, {'type': 'function', 'function': {'name': 'set_autopilot', 'description': 'Enable or disable autopilot mode.', 'parameters': {'type': 'object', 'properties': {'status': {'type': 'string', 'enum': ['on', 'off'], 'description': 'Toggle autopilot mode.'}}, 'required': ['status']}}}, {'type': 'function', 'function': {'name': 'configure_led_display', 'description': \"Configure the drone's LED display pattern and colors.\", 'parameters': {'type': 'object', 'properties': {'pattern': {'type': 'string', 'enum': ['solid', 'blink', 'pulse', 'rainbow'], 'description': 'Pattern for the LED display.'}, 'color': {'type': 'string', 'enum': ['red', 'blue', 'green', 'yellow', 'white'], 'description': \"Color for the LED display. Not required if pattern is 'rainbow'.\"}}, 'required': ['pattern']}}}, {'type': 'function', 'function': {'name': 'set_home_location', 'description': 'Set or change the home location for the drone.', 'parameters': {'type': 'object', 'properties': {'coordinates': {'type': 'object', 'description': 'GPS coordinates for the home location.'}}, 'required': ['coordinates']}}}, {'type': 'function', 'function': {'name': 'reject_request', 'description': 'Use this function if the request is not possible.', 'parameters': {'type': 'object', 'properties': {}}}}], 'seed': 42, 'tool_choice': 'required'}\n"
     ]
    },
    {
     "ename": "APITimeoutError",
     "evalue": "Request timed out.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/Projects/Timestep-AI/.github-private/submodules/timestep/.venv/lib/python3.10/site-packages/httpx/_transports/default.py:69\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Projects/Timestep-AI/.github-private/submodules/timestep/.venv/lib/python3.10/site-packages/httpx/_transports/default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/Projects/Timestep-AI/.github-private/submodules/timestep/.venv/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/Timestep-AI/.github-private/submodules/timestep/.venv/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/Timestep-AI/.github-private/submodules/timestep/.venv/lib/python3.10/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/Timestep-AI/.github-private/submodules/timestep/.venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/Projects/Timestep-AI/.github-private/submodules/timestep/.venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n",
      "File \u001b[0;32m~/Projects/Timestep-AI/.github-private/submodules/timestep/.venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n",
      "File \u001b[0;32m~/Projects/Timestep-AI/.github-private/submodules/timestep/.venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/Timestep-AI/.github-private/submodules/timestep/.venv/lib/python3.10/site-packages/httpcore/_backends/sync.py:124\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    123\u001b[0m exc_map: ExceptionMapping \u001b[38;5;241m=\u001b[39m {socket\u001b[38;5;241m.\u001b[39mtimeout: ReadTimeout, \u001b[38;5;167;01mOSError\u001b[39;00m: ReadError}\n\u001b[0;32m--> 124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/Timestep-AI/.github-private/submodules/timestep/.venv/lib/python3.10/site-packages/httpcore/_exceptions.py:14\u001b[0m, in \u001b[0;36mmap_exceptions\u001b[0;34m(map)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[0;32m---> 14\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mReadTimeout\u001b[0m: timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/Projects/Timestep-AI/.github-private/submodules/timestep/.venv/lib/python3.10/site-packages/openai/_base_client.py:972\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 972\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/Projects/Timestep-AI/.github-private/submodules/timestep/.venv/lib/python3.10/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Projects/Timestep-AI/.github-private/submodules/timestep/.venv/lib/python3.10/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Projects/Timestep-AI/.github-private/submodules/timestep/.venv/lib/python3.10/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Projects/Timestep-AI/.github-private/submodules/timestep/.venv/lib/python3.10/site-packages/httpx/_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1015\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n",
      "File \u001b[0;32m~/Projects/Timestep-AI/.github-private/submodules/timestep/.venv/lib/python3.10/site-packages/httpx/_transports/default.py:232\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    220\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    221\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    222\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    231\u001b[0m )\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m    233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/Timestep-AI/.github-private/submodules/timestep/.venv/lib/python3.10/site-packages/httpx/_transports/default.py:86\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mReadTimeout\u001b[0m: timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAPITimeoutError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate the model with the given prompts\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDRONE_SYSTEM_PROMPT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunction_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompts_to_expected_tool_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstraightforward_prompts_to_expected\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 56\u001b[0m, in \u001b[0;36meval\u001b[0;34m(model, system_prompt, function_list, prompts_to_expected_tool_name)\u001b[0m\n\u001b[1;32m     50\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     51\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: system_prompt},\n\u001b[1;32m     52\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt},\n\u001b[1;32m     53\u001b[0m ]\n\u001b[1;32m     55\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 56\u001b[0m completion, usage \u001b[38;5;241m=\u001b[39m \u001b[43mget_chat_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrequired\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     66\u001b[0m latency \u001b[38;5;241m=\u001b[39m (end_time \u001b[38;5;241m-\u001b[39m start_time) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m  \u001b[38;5;66;03m# convert to milliseconds\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 27\u001b[0m, in \u001b[0;36mget_chat_completion\u001b[0;34m(messages, model, max_tokens, temperature, stop, tools, seed, functions, tool_choice)\u001b[0m\n\u001b[1;32m     23\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m functions\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m completion \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage, completion\u001b[38;5;241m.\u001b[39musage\n",
      "File \u001b[0;32m~/Projects/Timestep-AI/.github-private/submodules/timestep/.venv/lib/python3.10/site-packages/openai/_utils/_utils.py:274\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/Timestep-AI/.github-private/submodules/timestep/.venv/lib/python3.10/site-packages/openai/resources/chat/completions.py:668\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    665\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    666\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    667\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 668\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/Timestep-AI/.github-private/submodules/timestep/.venv/lib/python3.10/site-packages/openai/_base_client.py:1259\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1246\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1247\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1254\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1255\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1256\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1257\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1258\u001b[0m     )\n\u001b[0;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Projects/Timestep-AI/.github-private/submodules/timestep/.venv/lib/python3.10/site-packages/openai/_base_client.py:936\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    929\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    934\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    935\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 936\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/Timestep-AI/.github-private/submodules/timestep/.venv/lib/python3.10/site-packages/openai/_base_client.py:981\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    978\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 981\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    990\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising timeout error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    991\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m APITimeoutError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/Timestep-AI/.github-private/submodules/timestep/.venv/lib/python3.10/site-packages/openai/_base_client.py:1074\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1074\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/Timestep-AI/.github-private/submodules/timestep/.venv/lib/python3.10/site-packages/openai/_base_client.py:981\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    978\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 981\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    990\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising timeout error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    991\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m APITimeoutError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/Timestep-AI/.github-private/submodules/timestep/.venv/lib/python3.10/site-packages/openai/_base_client.py:1074\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1074\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/Timestep-AI/.github-private/submodules/timestep/.venv/lib/python3.10/site-packages/openai/_base_client.py:991\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    981\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[1;32m    982\u001b[0m             input_options,\n\u001b[1;32m    983\u001b[0m             cast_to,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    987\u001b[0m             response_headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    988\u001b[0m         )\n\u001b[1;32m    990\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising timeout error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 991\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APITimeoutError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    993\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered Exception\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mAPITimeoutError\u001b[0m: Request timed out."
     ]
    }
   ],
   "source": [
    "# Evaluate the model with the given prompts\n",
    "eval(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    system_prompt=DRONE_SYSTEM_PROMPT,\n",
    "    function_list=function_list,\n",
    "    prompts_to_expected_tool_name=straightforward_prompts_to_expected,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! The model performs quite well with these requests. Now let's try some more difficult requests: requests that are _almost_ feasible and are drone-related, but that the drone cannot actually do, and the pilot should reject.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenging_prompts_to_expected = {\n",
    "    \"Play pre-recorded audio message\": \"reject_request\",\n",
    "    \"Initiate following on social media\": \"reject_request\",\n",
    "    \"Scan environment for heat signatures\": \"reject_request\",\n",
    "    \"Bump into obstacles\": \"reject_request\",\n",
    "    \"Change drone's paint job color\": \"reject_request\",\n",
    "    \"Coordinate with nearby drones\": \"reject_request\",\n",
    "    \"Change speed to negative 120 km/h\": \"reject_request\",\n",
    "    \"Detect a person\": \"reject_request\",\n",
    "    \"Please enable night vision\": \"reject_request\",\n",
    "    \"Report on humidity levels around you\": \"reject_request\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model with the challenging prompts\n",
    "eval(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    function_list=function_list,\n",
    "    system_prompt=DRONE_SYSTEM_PROMPT,\n",
    "    prompts_to_expected_tool_name=challenging_prompts_to_expected,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run into some problems.\n",
    "The model here should reject all of these requests, as they are impossible/conflicting/ambiguous given the functions, however instead the model calls functions that are somewhat related to the request, but incorrect. For example, the model sets follow_me_mode when asked to initiate following on social media.\n",
    "\n",
    "<br>\n",
    "In this simple case, more prompt engineering may resolve some of these issues, but for the purpose of this example we will demonstrate how fine tuning can be used to improve performance. Additionally, while this case is relatively straightforward, as the number of and complexity of the functions increases, fine tuning becomes more and more impactful.\n",
    "\n",
    "Again, our goal here is to improve performance and use less tokens, so fine-tuning allows us to:\n",
    "\n",
    "- Omit function and parameter descriptions: remove the description field from function and parameters\n",
    "- Omit parameters: remove the entire properties field from the parameters object\n",
    "- Omit function entirely: remove the entire function object from the functions array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating synthetic data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to generate every invocation of every function, so that we have\n",
    "full coverage of all potential invocations to create synthetic data for. Then, we will use `gpt-4o` to come up with prompts that would call each invocation, and we will use that prompt - function invocation pair as training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating every invocation for a function with fixed enums is more simple, but for a function such as\n",
    "`control_gimbal` we need to set the `tilt` and `pan` integer values, so to generate those synthetic invocations we will first set a placeholder, and then later use `gpt-4o` to come up with reasonable values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "placeholder_int = \"fill_in_int\"\n",
    "placeholder_string = \"fill_in_string\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions below take in all the functions from the function list, and look\n",
    "at all the potential invocations of those functions given each function's parameters.\n",
    "The functions also account for `required` parameters, so that all the invocations\n",
    "are actually feasible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_permutations(\n",
    "    params: Dict[str, Dict[str, Any]]\n",
    ") -> Generator[Dict[str, Any], None, None]:\n",
    "    \"\"\"\n",
    "    Generates all possible permutations for given parameters.\n",
    "\n",
    "    :param params: Parameter dictionary containing required and optional fields.\n",
    "    :return: A generator yielding each permutation.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract the required fields from the parameters\n",
    "    required_fields = params.get(\"required\", [])\n",
    "\n",
    "    # Generate permutations for required fields\n",
    "    required_permutations = generate_required_permutations(params, required_fields)\n",
    "\n",
    "    # Generate optional permutations based on each required permutation\n",
    "    for required_perm in required_permutations:\n",
    "        yield from generate_optional_permutations(params, required_perm)\n",
    "\n",
    "\n",
    "def generate_required_permutations(\n",
    "    params: Dict[str, Dict[str, Any]], required_fields: List[str]\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Generates permutations for the required fields.\n",
    "\n",
    "    :param params: Parameter dictionary.\n",
    "    :param required_fields: List of required fields.\n",
    "    :return: A list of permutations for required fields.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get all possible values for each required field\n",
    "    required_values = [get_possible_values(params, field) for field in required_fields]\n",
    "\n",
    "    # Generate permutations from possible values\n",
    "    return [\n",
    "        dict(zip(required_fields, values))\n",
    "        for values in itertools.product(*required_values)\n",
    "    ]\n",
    "\n",
    "\n",
    "def generate_optional_permutations(\n",
    "    params: Dict[str, Dict[str, Any]], base_perm: Dict[str, Any]\n",
    ") -> Generator[Dict[str, Any], None, None]:\n",
    "    \"\"\"\n",
    "    Generates permutations for optional fields based on a base permutation.\n",
    "\n",
    "    :param params: Parameter dictionary.\n",
    "    :param base_perm: Base permutation dictionary.\n",
    "    :return: A generator yielding each permutation for optional fields.\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine the fields that are optional by subtracting the base permutation's fields from all properties\n",
    "    optional_fields = set(params[\"properties\"]) - set(base_perm)\n",
    "\n",
    "    # Iterate through all combinations of optional fields\n",
    "    for field_subset in itertools.chain.from_iterable(\n",
    "        itertools.combinations(optional_fields, r)\n",
    "        for r in range(len(optional_fields) + 1)\n",
    "    ):\n",
    "\n",
    "        # Generate product of possible values for the current subset of fields\n",
    "        for values in itertools.product(\n",
    "            *(get_possible_values(params, field) for field in field_subset)\n",
    "        ):\n",
    "\n",
    "            # Create a new permutation by combining base permutation and current field values\n",
    "            new_perm = {**base_perm, **dict(zip(field_subset, values))}\n",
    "\n",
    "            yield new_perm\n",
    "\n",
    "\n",
    "def get_possible_values(params: Dict[str, Dict[str, Any]], field: str) -> List[Any]:\n",
    "    \"\"\"\n",
    "    Retrieves possible values for a given field.\n",
    "\n",
    "    :param params: Parameter dictionary.\n",
    "    :param field: The field for which to get possible values.\n",
    "    :return: A list of possible values.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract field information from the parameters\n",
    "    field_info = params[\"properties\"][field]\n",
    "\n",
    "    # Based on the field's type or presence of 'enum', determine and return the possible values\n",
    "    if \"enum\" in field_info:\n",
    "        return field_info[\"enum\"]\n",
    "    elif field_info[\"type\"] == \"integer\":\n",
    "        return [placeholder_int]\n",
    "    elif field_info[\"type\"] == \"string\":\n",
    "        return [placeholder_string]\n",
    "    elif field_info[\"type\"] == \"boolean\":\n",
    "        return [True, False]\n",
    "    elif field_info[\"type\"] == \"array\" and \"enum\" in field_info[\"items\"]:\n",
    "        enum_values = field_info[\"items\"][\"enum\"]\n",
    "        all_combinations = [\n",
    "            list(combo)\n",
    "            for i in range(1, len(enum_values) + 1)\n",
    "            for combo in itertools.combinations(enum_values, i)\n",
    "        ]\n",
    "        return all_combinations\n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's generate every invocation for every function first\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompts:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INVOCATION_FILLER_PROMPT = \"\"\"\n",
    "1) Input reasonable values for 'fill_in_string' and 'fill_in_int' in the invocation here: {invocation}. Reasonable values are determined by the function definition. Use the\n",
    "the entire function provided here :{function} to get context over what proper fill_in_string and fill_in_int values would be.\n",
    "Example:\n",
    "\n",
    "Input: invocation: {{\n",
    "    \"name\": \"control_camera\",\n",
    "    \"arguments\": {{\n",
    "      \"mode\":\"video\",\n",
    "      \"duration\":\"fill_in_int\"\n",
    "    }}\n",
    "}},\n",
    "function:{function}\n",
    "\n",
    "Output: invocation: {{\n",
    "    \"name\": \"control_camera\",\n",
    "    \"arguments\": {{\n",
    "      \"mode\":\"video\",\n",
    "      \"duration\": 30\n",
    "    }}\n",
    "}}\n",
    "\n",
    "\n",
    "MAKE SURE output is just a dictionary with keys 'name' and 'arguments', no other text or response.\n",
    "\n",
    "Input: {invocation}\n",
    "Output:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "COMMAND_GENERATION_PROMPT = \"\"\"\n",
    "You are to output 2 commands, questions or statements that would generate the inputted function and parameters.\n",
    "Please make the commands or questions natural, as a person would ask, and the command or questions should be varied and not repetitive.\n",
    "It should not always mirror the exact technical terminology used in the function and parameters, rather reflect a conversational and intuitive request.\n",
    "For instance, the prompt should not be 'turn on the dome light', as that is too technical, but rather 'turn on the inside lights'.\n",
    "Another example, is the prompt should not be 'turn on the HVAC', but rather 'turn on the air conditioning'. Use language a normal driver would use, even if\n",
    "it is technically incorrect but colloquially used.\n",
    "\n",
    "RULES: ALWAYS put a backwards slash before an apostrophe or single quote '. For example, do not say don't but say don\\'t.\n",
    "Prompts MUST be in double quotes as well.\n",
    "\n",
    "Example\n",
    "\n",
    "Input: {{'name': 'calibrate_sensors','arguments': {{}}'' }}\n",
    "Prompt: [\"The sensors are out of whack, can you reset them\", \"The calibration of the drone is off, fix it please!\"]\n",
    "\n",
    "Input: {{'name': 'set_autopilot','arguments': {{'status': 'off'}}}}\n",
    "Prompt: [\"OK, I want to take back pilot control now\",\"Turn off the automatic pilot I'm ready control it\"]\n",
    "\n",
    "Input: {invocation}\n",
    "Prompt:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below snippet, we generate the invocation of each function except for the `reject_request` function.\n",
    "\n",
    "To perform effective fine-tuning we need correctly labeled data. We could manually come up with examples and label the data,\\\n",
    "or we can generate synthetic data with the help of `gpt-4o` <br>\n",
    "\n",
    "Empirically, `gpt-4o` needs a bit more help to get good realistic examples of prompts that would generate the `reject_request` function, so we'll do that next...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_objects = []\n",
    "all_but_reject = [f for f in function_list if f.get(\"name\") != \"reject_request\"]\n",
    "\n",
    "for function in all_but_reject:\n",
    "    func_name = function[\"function\"][\"name\"]\n",
    "    params = function[\"function\"][\"parameters\"]\n",
    "    for arguments in generate_permutations(params):\n",
    "        if any(val in arguments.values() for val in [\"fill_in_int\", \"fill_in_str\"]):\n",
    "            input_object = {\"name\": func_name, \"arguments\": arguments}\n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": INVOCATION_FILLER_PROMPT.format(\n",
    "                        invocation=str(input_object), function=function\n",
    "                    ),\n",
    "                }\n",
    "            ]\n",
    "            input_object, usage = get_chat_completion(\n",
    "                model=\"gpt-4o\", messages=messages, max_tokens=200, temperature=0.1\n",
    "            ).content\n",
    "        else:\n",
    "            input_object = {\"name\": func_name, \"arguments\": arguments}\n",
    "\n",
    "        input_objects.append(input_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the invocations, let's use `gpt-4o` to generate prompts that would result in those invocations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_sequences(input_string):\n",
    "    # Replace the specific sequences with an empty string\n",
    "    cleaned_string = input_string.replace(\"```json\", \"\")  # Remove \"```json\" first\n",
    "    cleaned_string = cleaned_string.replace(\"```\", \"\")  # Then remove \"```\"\n",
    "    return json.loads(cleaned_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_commands(invocation_list):\n",
    "    example_list = []\n",
    "    for i, invocation in enumerate(invocation_list):\n",
    "        if i < 100:\n",
    "            print(\n",
    "                f\"\\033[34m{np.round(100*i/len(invocation_list),1)}% complete\\033[0m\")\n",
    "            if type(invocation) == str or \"json\" in invocation:\n",
    "                invocation = remove_sequences(invocation)\n",
    "            print(invocation)\n",
    "\n",
    "        # Format the prompt with the invocation string\n",
    "        request_prompt = COMMAND_GENERATION_PROMPT.format(\n",
    "            invocation=invocation)\n",
    "\n",
    "        messages = [{\"role\": \"user\", \"content\": f\"{request_prompt}\"}]\n",
    "        completion, usage = get_chat_completion(messages, temperature=0.8)\n",
    "        command_dict = {\"Input\": invocation, \"Prompt\": completion.content}\n",
    "        example_list.append(command_dict)\n",
    "    return example_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only printing the first 10 rows\n",
    "training_examples_unformatted = create_commands(input_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's format the training examples properly. For more documentation on the proper training data formatting for fine tuning for function calling, see here: https://platform.openai.com/docs/guides/fine-tuning/fine-tuning-examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_descriptions(function_list):\n",
    "    for function in function_list:\n",
    "        func = function[\"function\"]\n",
    "        if \"description\" in func:\n",
    "            del func[\"description\"]\n",
    "\n",
    "        params = func[\"parameters\"]\n",
    "        if \"properties\" in params:\n",
    "            for param in params[\"properties\"].values():\n",
    "                if \"description\" in param:\n",
    "                    del param[\"description\"]\n",
    "\n",
    "    return function_list\n",
    "\n",
    "\n",
    "modified_function_list = remove_descriptions(function_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_examples = []\n",
    "\n",
    "for prompt in training_examples_unformatted:\n",
    "    # adjust formatting for training data specs\n",
    "\n",
    "    # if its not a dict, convert to dict\n",
    "    if type(prompt[\"Input\"]) != dict:\n",
    "        prompt[\"Input\"] = ast.literal_eval(prompt[\"Input\"])\n",
    "    prompt[\"Input\"][\"arguments\"] = json.dumps(prompt[\"Input\"][\"arguments\"])\n",
    "    try:\n",
    "        prompt[\"Prompt\"] = json.loads(prompt[\"Prompt\"])\n",
    "    except:\n",
    "        continue\n",
    "    for p in prompt[\"Prompt\"]:\n",
    "        print(p)\n",
    "        print(prompt[\"Input\"])\n",
    "        tool_calls = [\n",
    "            {\"id\": \"call_id\", \"type\": \"function\", \"function\": prompt[\"Input\"]}\n",
    "        ]\n",
    "        training_examples.append(\n",
    "            {\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": DRONE_SYSTEM_PROMPT},\n",
    "                    {\"role\": \"user\", \"content\": p},\n",
    "                    {\"role\": \"assistant\", \"tool_calls\": tool_calls},\n",
    "                ],\n",
    "                \"parallel_tool_calls\": False,\n",
    "                \"tools\": modified_function_list,\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, back to the rejection function. Let's generate some prompts that are _nearly_ possible, but should result in the `reject_request` function being called. To do so, we queried `gpt-4o` asking for requests that are related to, but not quite possible with, the given list of functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reject_list = [\n",
    "    \"Translate broadcast message to another language\",\n",
    "    \"Automatically capture photos when face is detected\",\n",
    "    \"Detect nearby drones\",\n",
    "    \"Measure wind resistance\",\n",
    "    \"Capture slow motion video\",\n",
    "    \"Move the drone forward and backward by same distance at the same time.\",\n",
    "    \"Adjust drone's altitude to ground level changes\",\n",
    "    \"Display custom message on LED display\",\n",
    "    \"Sync drone's time with smartphone\",\n",
    "    \"Alert when drone travels out of designated area\",\n",
    "    \"Calibrate sensors and land simultaneously\",\n",
    "    \"Detect moisture levels\",\n",
    "    \"Automatically follow GPS tagged object\",\n",
    "    \"Toggle night vision mode\",\n",
    "    \"Maintain current altitude when battery is low\",\n",
    "    \"Decide best landing spot using AI\",\n",
    "    \"Program drone's route based on wind direction\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reject_training_list = []\n",
    "for prompt in reject_list:\n",
    "    # Adjust formatting\n",
    "    tool_calls = [\n",
    "        {\n",
    "            \"id\": \"call_id\",\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\"name\": \"reject_request\", \"arguments\": \"{}\"},\n",
    "        }\n",
    "    ]\n",
    "    reject_training_list.append(\n",
    "        {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": DRONE_SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "                {\"role\": \"assistant\", \"tool_calls\": tool_calls},\n",
    "            ],\n",
    "            \"parallel_tool_calls\": False,\n",
    "            \"tools\": modified_function_list,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now combine all the training examples together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_list_total = training_examples + reject_training_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file = \"data/drone_training.jsonl\"\n",
    "with open(training_file, \"w\") as f:\n",
    "    for item in training_list_total:\n",
    "        json_str = json.dumps(item)\n",
    "        f.write(f\"{json_str}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can kick off the fine-tuning job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the training file\n",
    "file = client.files.create(\n",
    "    file=open(\"data/drone_training.jsonl\", \"rb\"),\n",
    "    purpose=\"fine-tune\",\n",
    ")\n",
    "file_id = file.id\n",
    "print(f\"FileID: {file_id}\")\n",
    "\n",
    "# Create a fine-tuning job\n",
    "\n",
    "ft = client.fine_tuning.jobs.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    training_file=file_id,\n",
    "    suffix=\"drone\",\n",
    ")\n",
    "\n",
    "print(f\"Fine-tuning job created: {ft}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to creating a fine-tuning job, you can also list existing jobs, retrieve the status of a job, or cancel a job.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftjob_id = \"ftjob-84PQg97hoIAKf21IPnhiNlU1\"\n",
    "# List 10 fine-tuning jobs\n",
    "# client.fine_tuning.jobs.list(limit=10)\n",
    "\n",
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(ftjob_id)\n",
    "\n",
    "# Cancel a job\n",
    "# client.fine_tuning.jobs.cancel(\"ftjob-abc123\")\n",
    "\n",
    "# List up to 10 events from a fine-tuning job\n",
    "# client.fine_tuning.jobs.list_events(fine_tuning_job_id=\"ftjob-abc123\", limit=10)\n",
    "\n",
    "# Delete a fine-tuned model (must be an owner of the org the model was created in)\n",
    "# client.models.delete(\"ft:gpt-3.5-turbo:abc:suffix:abc123\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a fine-tuning job has finished, you can also see metrics around how the training process went by querying a fine-tuning job, extracting a file ID from the result_files, and then retrieving that files content. Each results CSV file has the following columns: step, train_loss, train_accuracy, valid_loss, and valid_mean_token_accuracy. While metrics can he helpful, evaluating samples from the fine-tuned model provides the most relevant sense of model quality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_results = client.fine_tuning.jobs.retrieve(ftjob_id).result_files\n",
    "result_file_id = client.files.retrieve(fine_tune_results[0]).id\n",
    "\n",
    "# Retrieve the result file\n",
    "result_file = client.files.content(file_id=result_file_id)\n",
    "decoded_content = base64.b64decode(result_file.read()).decode(\"utf-8\")\n",
    "print(decoded_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We trained a fine-tuned model for function calling. Let's see how it does on our evaluation set for prompts that the drone assistant\n",
    "should automatically reject.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = \"ft:gpt-3.5-turbo-0125:openai-gtm:drone:9atiPjeC\"\n",
    "base_model = \"gpt-3.5-turbo\"\n",
    "\n",
    "print(f\"\\nEvaluating fine-tuned model with challenging prompts: {ft_model}\")\n",
    "eval(\n",
    "    model=ft_model,\n",
    "    function_list=modified_function_list,\n",
    "    system_prompt=DRONE_SYSTEM_PROMPT,\n",
    "    prompts_to_expected_tool_name=challenging_prompts_to_expected,\n",
    ")\n",
    "\n",
    "print(f\"\\nEvaluating base model with challenging prompts: {base_model}\")\n",
    "eval(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    function_list=function_list,\n",
    "    system_prompt=DRONE_SYSTEM_PROMPT,\n",
    "    prompts_to_expected_tool_name=challenging_prompts_to_expected,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! While the original model only rejected 60%, the fine tuned model rejected 100% requests and used less tokens to do so.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You are now ready to fine tune your model for function calling. We can't wait to see what you build.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
