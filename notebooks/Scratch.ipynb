{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from openai import OpenAI, Stream\n",
    "from openai.types.beta.assistant_stream_event import AssistantStreamEvent\n",
    "\n",
    "from timestep.config import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\", settings.openai_api_key),\n",
    "    # base_url=os.getenv(\"OPENAI_BASE_URL\", settings.openai_base_url),\n",
    "    base_url=\"http://127.0.0.1:8080/v1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gorilla.cs.berkeley.edu/blogs/8_berkeley_function_calling_leaderboard.html#prompt\n",
    "SYSTEM_PROMPT_FOR_CHAT_MODEL = \"\"\"\n",
    "You are an expert in composing functions. You are given a question and a set of possible functions.\n",
    "Based on the question, you will need to make one or more function/tool calls to achieve the purpose.\n",
    "If none of the function can be used, point it out. If the given question lacks the parameters required by the function, also point it out. You should only return the function call in tools call sections.\n",
    "\"\"\"\n",
    "\n",
    "USER_MESSAGE_FOR_CHAT_MODEL = \"Questions:{user_prompt}\\nHere is a list of functions in JSON format that you can invoke:\\n{functions}. Should you decide to return the function call(s), NO other text MUST be included.\"\n",
    "\n",
    "# https://github.com/BerriAI/litellm/blob/feb8c3c5b439cad22d26eeb49852207e3820665d/litellm/llms/prompt_templates/factory.py#L2443\n",
    "# Function call template\n",
    "def function_call_prompt(messages: list, functions: list):\n",
    "    # function_prompt = \"\"\"Produce JSON OUTPUT ONLY! Adhere to this format {\"name\": \"function_name\", \"arguments\":{\"argument_name\": \"argument_value\"}} The following functions are available to you:\"\"\"\n",
    "    function_prompt = SYSTEM_PROMPT_FOR_CHAT_MODEL + \"\\nHere is a list of functions in JSON format that you can invoke:\\n\"\n",
    "\n",
    "    # function_prompt = \"Produce JSON OUTPUT ONLY! Adhere to this format {'tool_calls': [{'name': 'function_name', 'arguments': {'argument_name': 'argument_value'}}]} The following functions are available to you:\"\n",
    "\n",
    "    for function in functions:\n",
    "        function_prompt += f\"\"\"\\n{function}\\n\"\"\"\n",
    "\n",
    "    # function_prompt += \"\\nShould you decide to return the function call(s), NO other text MUST be included.\"\n",
    "\n",
    "    function_added_to_prompt = False\n",
    "    for message in messages:\n",
    "        if \"system\" in message[\"role\"]:\n",
    "            message[\"content\"] += f\"\"\" {function_prompt}\"\"\"\n",
    "            function_added_to_prompt = True\n",
    "\n",
    "    if function_added_to_prompt == False:\n",
    "        messages.append({\"role\": \"system\", \"content\": f\"\"\"{function_prompt}\"\"\"})\n",
    "        # messages = [{\"role\": \"system\", \"content\": f\"\"\"{function_prompt}\"\"\"}] + messages\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': \"What's the weather like in San Francisco, Tokyo, and Paris?\"}, {'role': 'system', 'content': \"\\nYou are an expert in composing functions. You are given a question and a set of possible functions.\\nBased on the question, you will need to make one or more function/tool calls to achieve the purpose.\\nIf none of the function can be used, point it out. If the given question lacks the parameters required by the function, also point it out. You should only return the function call in tools call sections.\\n\\nHere is a list of functions in JSON format that you can invoke:\\n\\n{'name': 'get_current_weather', 'description': 'Get the current weather in a given location', 'parameters': {'type': 'object', 'properties': {'location': {'type': 'string', 'description': 'The city and state, e.g. San Francisco, CA'}, 'unit': {'type': 'string', 'enum': ['celsius', 'fahrenheit']}}, 'required': ['location']}}\\n\"}]\n",
      "ChatCompletion(id='chatcmpl-3dcIL4SqLrmGEGIgT7mNzpiYE4gbOA3v', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"{'location': 'San Francisco, CA', 'unit': 'celsius'}</s>\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1723926859, model='gpt-4o', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=18, prompt_tokens=245, total_tokens=263))\n"
     ]
    }
   ],
   "source": [
    "# tools = [\n",
    "#     {\n",
    "#         \"type\": \"function\",\n",
    "#         \"function\": {\n",
    "#             \"name\": \"get_weather\",\n",
    "#             \"strict\": True,\n",
    "#             \"parameters\": {\n",
    "#                 \"type\": \"object\",\n",
    "#                 \"properties\": {\n",
    "#                     \"location\": {\"type\": \"string\"},\n",
    "#                     \"unit\": {\"type\": \"string\", \"enum\": [\"c\", \"f\"]},\n",
    "#                 },\n",
    "#                 \"required\": [\"location\", \"unit\"],\n",
    "#                 \"additionalProperties\": False,\n",
    "#             },\n",
    "#         },\n",
    "#     },\n",
    "    # {\n",
    "    #     \"type\": \"function\",\n",
    "    #     \"function\": {\n",
    "    #         \"name\": \"get_stock_price\",\n",
    "    #         \"strict\": True,\n",
    "    #         \"parameters\": {\n",
    "    #             \"type\": \"object\",\n",
    "    #             \"properties\": {\n",
    "    #                 \"symbol\": {\"type\": \"string\"},\n",
    "    #             },\n",
    "    #             \"required\": [\"symbol\"],\n",
    "    #             \"additionalProperties\": False,\n",
    "    #         },\n",
    "    #     },\n",
    "    # },\n",
    "# ]\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "# messages = [\n",
    "#     # {\"role\": \"system\", \"content\": SYSTEM_PROMPT_FOR_CHAT_MODEL},\n",
    "#     # {\"role\": \"user\", \"content\": \"What's the weather like in Boston today?\"},\n",
    "#     # {\"role\": \"user\", \"content\": USER_MESSAGE_FOR_CHAT_MODEL.format(user_prompt=\"What's the weather like in Boston today?\", functions=tools)},\n",
    "# ]\n",
    "\n",
    "functions = [tool[\"function\"] for tool in tools]\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"What's the weather like in San Francisco, Tokyo, and Paris?\"}]\n",
    "\n",
    "# messages = function_call_prompt(messages, tools)\n",
    "messages = function_call_prompt(messages, functions)\n",
    "\n",
    "print(messages)\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    # highlight-start\n",
    "    # tool_choice=\"required\"\n",
    "    tool_choice=\"auto\"\n",
    "    # highlight-end\n",
    ")\n",
    "\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "stop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: stop"
     ]
    }
   ],
   "source": [
    "raise Exception(\"stop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.embeddings.create(\n",
    "    input=\"Your text string goes here\",\n",
    "    model=\"text-embedding-3-small\"\n",
    ")\n",
    "\n",
    "print(response.data[0].embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(response.data[0].embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    model=\"gpt-4o\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "  {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"get_current_weather\",\n",
    "      \"description\": \"Get the current weather in a given location\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"location\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "          },\n",
    "          \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "        },\n",
    "        \"required\": [\"location\"],\n",
    "      },\n",
    "    }\n",
    "  }\n",
    "]\n",
    "\n",
    "stream: Stream[AssistantStreamEvent] = client.beta.threads.create_and_run(\n",
    "  thread={\n",
    "      \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"What is the weather like in San Francisco?\"}\n",
    "      ]\n",
    "  },\n",
    "  # assistant_id=\"asst_abc123\",\n",
    "  assistant_id=assistant.id,\n",
    "  tools=tools,\n",
    "  stream=True\n",
    ")\n",
    "\n",
    "try:\n",
    "  for event in stream:\n",
    "    print(event)\n",
    "\n",
    "finally:\n",
    "  client.beta.assistants.delete(assistant.id)\n",
    "  stream.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
