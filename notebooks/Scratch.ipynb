{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from openai import OpenAI, Stream\n",
    "from openai.types.chat.chat_completion_chunk import ChatCompletionChunk\n",
    "from openai.types.chat.chat_completion import ChatCompletion\n",
    "from openai.types.completion import Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    base_url=os.environ.get(\"OPENAI_BASE_URL\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"How can the net amount of entropy of the universe be massively decreased?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', and it was very special.\\nMummy said, \"I\\'m so proud of you for being so kind. I\\'ll help you make a new home.\"\\nThe family smiled and said, \"Yes, we can help!\"\\nThey all went to the woods and found a big tree with lots of leaves. They put the branches in the sky and started to look at them.\\nThe kids were very happy and thanked the tree for helping them. They had made a new home and they were so proud of their work.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_completion: ChatCompletion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You an AI assistant. Your top priority is responding to user questions with truthful answers.\"},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ],\n",
    "    model=\"LLaMA_CPP\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "full_reply_content = chat_completion.choices[0].message.content\n",
    "full_reply_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=None, function_call=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=',', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' and', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' and', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' it', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' it', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' was', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' was', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' very', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' very', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' special', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' special', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content='.', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content='\\n', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content='\\n', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content='M', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content='M', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content='ummy', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content='ummy', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' said', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' said', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=',', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' \"', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' \"', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content='I', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content='I', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=\"'\", function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=\"'\", function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content='m', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content='m', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' so', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' so', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' proud', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' proud', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' of', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' of', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' you', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' you', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' for', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' for', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' being', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' being', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' so', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' so', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' kind', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' kind', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content='.', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' I', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' I', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=\"'\", function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=\"'\", function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content='ll', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content='ll', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' help', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' help', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' you', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' you', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' make', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' make', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' a', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' a', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' new', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' new', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' home', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' home', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content='.\"', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content='.\"', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content='\\n', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content='\\n', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content='The', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content='The', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' family', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' family', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' smiled', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' smiled', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' and', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' and', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' said', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' said', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=',', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' \"', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' \"', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content='Yes', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content='Yes', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=',', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' we', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' we', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' can', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' can', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' help', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' help', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content='!\"', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content='!\"', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content='\\n', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content='\\n', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content='They', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content='They', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' all', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' all', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' went', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' went', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' to', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' to', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' the', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' the', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' woods', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' woods', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' and', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' and', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' found', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' found', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' a', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' a', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' big', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' big', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' tree', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' tree', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' with', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' with', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' lots', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' lots', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' of', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' of', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' leaves', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' leaves', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content='.', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' They', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' They', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' put', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' put', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' the', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' the', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' branches', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' branches', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' in', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' in', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' the', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' the', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' sky', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' sky', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' and', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' and', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' started', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' started', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' to', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' to', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' look', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' look', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' at', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' at', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' them', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' them', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content='.', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content='\\n', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content='\\n', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content='The', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content='The', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' kids', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' kids', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' were', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' were', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' very', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' very', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' happy', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' happy', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' and', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' and', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' thanked', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' thanked', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' the', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' the', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' tree', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' tree', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' for', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' for', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' helping', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' helping', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' them', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' them', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content='.', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' They', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' They', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' had', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' had', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' made', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' made', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' a', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' a', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' new', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' new', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' home', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' home', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' and', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' and', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' they', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' they', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' were', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' were', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' so', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' so', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' proud', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' proud', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' of', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' of', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' their', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' their', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=' work', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=' work', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content='.', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  ChatCompletionChunk(id='chatcmpl-790b3331-8959-4114-b20e-85e001f381ff', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=None), finish_reason='stop', index=0, logprobs=None)], created=1720818366, model='LLaMA_CPP', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "choices: [Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=None), finish_reason='stop', index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "', and it was very special.\\nMummy said, \"I\\'m so proud of you for being so kind. I\\'ll help you make a new home.\"\\nThe family smiled and said, \"Yes, we can help!\"\\nThey all went to the woods and found a big tree with lots of leaves. They put the branches in the sky and started to look at them.\\nThe kids were very happy and thanked the tree for helping them. They had made a new home and they were so proud of their work.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_completion_chunk_stream: Stream[ChatCompletionChunk] = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You an AI assistant. Your top priority is responding to user questions with truthful answers.\"},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ],\n",
    "    model=\"LLaMA_CPP\",\n",
    "    stream=True,\n",
    "    stream_options={\"include_usage\": True}, # retrieving token usage for stream response\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "collected_chunks = []\n",
    "collected_messages = []\n",
    "\n",
    "# iterate through the stream of events\n",
    "for chunk in chat_completion_chunk_stream:\n",
    "    collected_chunks.append(chunk)  # save the event response\n",
    "    print('chunk: ', chunk)\n",
    "    chunk_message = chunk.choices[0].delta.content  # extract the message\n",
    "    collected_messages.append(chunk_message)  # save the message\n",
    "    print(f\"choices: {chunk.choices}\\nusage: {chunk.usage}\")\n",
    "    print(\"****************\")\n",
    "\n",
    "# clean None in collected_messages\n",
    "collected_messages = [m for m in collected_messages if m is not None]\n",
    "full_reply_content = ''.join(collected_messages)\n",
    "full_reply_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Completion(id='cmpl-25739344-eb48-48a7-9545-9341148aea6a', choices=[CompletionChoice(finish_reason='length', index=0, logprobs=None, text=' He was very excited to see what was inside.\\nHe asked his mom,')], created=1720818367, model='LLaMA_CPP', object='text_completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=16, prompt_tokens=17, total_tokens=33))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion: Completion = client.completions.create(\n",
    "    model=\"LLaMA_CPP\",\n",
    "    prompt=user_prompt,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk:  Completion(id='cmpl-69ef6bf3-00f2-4700-bd0f-3f49921068d5', choices=[CompletionChoice(finish_reason=None, index=0, logprobs=None, text=' He')], created=1720818367, model='LLaMA_CPP', object='text_completion', system_fingerprint=None, usage=None)\n",
      "choices: [CompletionChoice(finish_reason=None, index=0, logprobs=None, text=' He')]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  Completion(id='cmpl-69ef6bf3-00f2-4700-bd0f-3f49921068d5', choices=[CompletionChoice(finish_reason=None, index=0, logprobs=None, text=' was')], created=1720818367, model='LLaMA_CPP', object='text_completion', system_fingerprint=None, usage=None)\n",
      "choices: [CompletionChoice(finish_reason=None, index=0, logprobs=None, text=' was')]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  Completion(id='cmpl-69ef6bf3-00f2-4700-bd0f-3f49921068d5', choices=[CompletionChoice(finish_reason=None, index=0, logprobs=None, text=' very')], created=1720818367, model='LLaMA_CPP', object='text_completion', system_fingerprint=None, usage=None)\n",
      "choices: [CompletionChoice(finish_reason=None, index=0, logprobs=None, text=' very')]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  Completion(id='cmpl-69ef6bf3-00f2-4700-bd0f-3f49921068d5', choices=[CompletionChoice(finish_reason=None, index=0, logprobs=None, text=' excited')], created=1720818367, model='LLaMA_CPP', object='text_completion', system_fingerprint=None, usage=None)\n",
      "choices: [CompletionChoice(finish_reason=None, index=0, logprobs=None, text=' excited')]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  Completion(id='cmpl-69ef6bf3-00f2-4700-bd0f-3f49921068d5', choices=[CompletionChoice(finish_reason=None, index=0, logprobs=None, text=' to')], created=1720818367, model='LLaMA_CPP', object='text_completion', system_fingerprint=None, usage=None)\n",
      "choices: [CompletionChoice(finish_reason=None, index=0, logprobs=None, text=' to')]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  Completion(id='cmpl-69ef6bf3-00f2-4700-bd0f-3f49921068d5', choices=[CompletionChoice(finish_reason=None, index=0, logprobs=None, text=' see')], created=1720818367, model='LLaMA_CPP', object='text_completion', system_fingerprint=None, usage=None)\n",
      "choices: [CompletionChoice(finish_reason=None, index=0, logprobs=None, text=' see')]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  Completion(id='cmpl-69ef6bf3-00f2-4700-bd0f-3f49921068d5', choices=[CompletionChoice(finish_reason=None, index=0, logprobs=None, text=' what')], created=1720818367, model='LLaMA_CPP', object='text_completion', system_fingerprint=None, usage=None)\n",
      "choices: [CompletionChoice(finish_reason=None, index=0, logprobs=None, text=' what')]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  Completion(id='cmpl-69ef6bf3-00f2-4700-bd0f-3f49921068d5', choices=[CompletionChoice(finish_reason=None, index=0, logprobs=None, text=' was')], created=1720818367, model='LLaMA_CPP', object='text_completion', system_fingerprint=None, usage=None)\n",
      "choices: [CompletionChoice(finish_reason=None, index=0, logprobs=None, text=' was')]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  Completion(id='cmpl-69ef6bf3-00f2-4700-bd0f-3f49921068d5', choices=[CompletionChoice(finish_reason=None, index=0, logprobs=None, text=' inside')], created=1720818367, model='LLaMA_CPP', object='text_completion', system_fingerprint=None, usage=None)\n",
      "choices: [CompletionChoice(finish_reason=None, index=0, logprobs=None, text=' inside')]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  Completion(id='cmpl-69ef6bf3-00f2-4700-bd0f-3f49921068d5', choices=[CompletionChoice(finish_reason=None, index=0, logprobs=None, text='.')], created=1720818367, model='LLaMA_CPP', object='text_completion', system_fingerprint=None, usage=None)\n",
      "choices: [CompletionChoice(finish_reason=None, index=0, logprobs=None, text='.')]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  Completion(id='cmpl-69ef6bf3-00f2-4700-bd0f-3f49921068d5', choices=[CompletionChoice(finish_reason=None, index=0, logprobs=None, text='\\n')], created=1720818367, model='LLaMA_CPP', object='text_completion', system_fingerprint=None, usage=None)\n",
      "choices: [CompletionChoice(finish_reason=None, index=0, logprobs=None, text='\\n')]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  Completion(id='cmpl-69ef6bf3-00f2-4700-bd0f-3f49921068d5', choices=[CompletionChoice(finish_reason=None, index=0, logprobs=None, text='He')], created=1720818367, model='LLaMA_CPP', object='text_completion', system_fingerprint=None, usage=None)\n",
      "choices: [CompletionChoice(finish_reason=None, index=0, logprobs=None, text='He')]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  Completion(id='cmpl-69ef6bf3-00f2-4700-bd0f-3f49921068d5', choices=[CompletionChoice(finish_reason=None, index=0, logprobs=None, text=' asked')], created=1720818367, model='LLaMA_CPP', object='text_completion', system_fingerprint=None, usage=None)\n",
      "choices: [CompletionChoice(finish_reason=None, index=0, logprobs=None, text=' asked')]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  Completion(id='cmpl-69ef6bf3-00f2-4700-bd0f-3f49921068d5', choices=[CompletionChoice(finish_reason=None, index=0, logprobs=None, text=' his')], created=1720818367, model='LLaMA_CPP', object='text_completion', system_fingerprint=None, usage=None)\n",
      "choices: [CompletionChoice(finish_reason=None, index=0, logprobs=None, text=' his')]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  Completion(id='cmpl-69ef6bf3-00f2-4700-bd0f-3f49921068d5', choices=[CompletionChoice(finish_reason=None, index=0, logprobs=None, text=' mom')], created=1720818367, model='LLaMA_CPP', object='text_completion', system_fingerprint=None, usage=None)\n",
      "choices: [CompletionChoice(finish_reason=None, index=0, logprobs=None, text=' mom')]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  Completion(id='cmpl-69ef6bf3-00f2-4700-bd0f-3f49921068d5', choices=[CompletionChoice(finish_reason=None, index=0, logprobs=None, text=',')], created=1720818367, model='LLaMA_CPP', object='text_completion', system_fingerprint=None, usage=None)\n",
      "choices: [CompletionChoice(finish_reason=None, index=0, logprobs=None, text=',')]\n",
      "usage: None\n",
      "****************\n",
      "chunk:  Completion(id='cmpl-69ef6bf3-00f2-4700-bd0f-3f49921068d5', choices=[CompletionChoice(finish_reason='length', index=0, logprobs=None, text='')], created=1720818367, model='LLaMA_CPP', object='text_completion', system_fingerprint=None, usage=None)\n",
      "choices: [CompletionChoice(finish_reason='length', index=0, logprobs=None, text='')]\n",
      "usage: None\n",
      "****************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' He was very excited to see what was inside.\\nHe asked his mom,'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_stream: Stream[Completion] = client.completions.create(\n",
    "    model=\"LLaMA_CPP\",\n",
    "    prompt=user_prompt,\n",
    "    stream=True,\n",
    "    stream_options={\"include_usage\": True}, # retrieving token usage for stream response\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "collected_chunks = []\n",
    "collected_messages = []\n",
    "\n",
    "# iterate through the stream of events\n",
    "for chunk in completion_stream:\n",
    "    collected_chunks.append(chunk)  # save the event response\n",
    "    print('chunk: ', chunk)\n",
    "    chunk_message = chunk.choices[0].text  # extract the message\n",
    "    collected_messages.append(chunk_message)  # save the message\n",
    "    print(f\"choices: {chunk.choices}\\nusage: {chunk.usage}\")\n",
    "    print(\"****************\")\n",
    "\n",
    "# clean None in collected_messages\n",
    "collected_messages = [m for m in collected_messages if m is not None]\n",
    "full_reply_content = ''.join(collected_messages)\n",
    "full_reply_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from llama_cpp import Llama\n",
    "from llama_cpp.llama_chat_format import MoondreamChatHandler, NanoLlavaChatHandler\n",
    "from llama_cpp.llama_tokenizer import LlamaHFTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file_name = \"tmp_recipe_finetune_training.jsonl\"\n",
    "validation_file_name = \"tmp_recipe_finetune_validation.jsonl\"\n",
    "\n",
    "# 3rdparty/openai-cookbook/examples/tmp_recipe_finetune_training.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.\"}, {\"role\": \"user\", \"content\": \"Title: No-Bake Nut Cookies\\\\n\\\\nIngredients: [\\\\\"1 c. firmly packed brown sugar\\\\\", \\\\\"1/2 c. evaporated milk\\\\\", \\\\\"1/2 tsp. vanilla\\\\\", \\\\\"1/2 c. broken nuts (pecans)\\\\\", \\\\\"2 Tbsp. butter or margarine\\\\\", \\\\\"3 1/2 c. bite size shredded rice biscuits\\\\\"]\\\\n\\\\nGeneric ingredients: \"}, {\"role\": \"assistant\", \"content\": \"[\\\\\"brown sugar\\\\\", \\\\\"milk\\\\\", \\\\\"vanilla\\\\\", \\\\\"nuts\\\\\", \\\\\"butter\\\\\", \\\\\"bite size shredded rice biscuits\\\\\"]\"}]}',\n",
       " '{\"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.\"}, {\"role\": \"user\", \"content\": \"Title: Jewell Ball\\'S Chicken\\\\n\\\\nIngredients: [\\\\\"1 small jar chipped beef, cut up\\\\\", \\\\\"4 boned chicken breasts\\\\\", \\\\\"1 can cream of mushroom soup\\\\\", \\\\\"1 carton sour cream\\\\\"]\\\\n\\\\nGeneric ingredients: \"}, {\"role\": \"assistant\", \"content\": \"[\\\\\"beef\\\\\", \\\\\"chicken breasts\\\\\", \\\\\"cream of mushroom soup\\\\\", \\\\\"sour cream\\\\\"]\"}]}',\n",
       " '{\"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.\"}, {\"role\": \"user\", \"content\": \"Title: Creamy Corn\\\\n\\\\nIngredients: [\\\\\"2 (16 oz.) pkg. frozen corn\\\\\", \\\\\"1 (8 oz.) pkg. cream cheese, cubed\\\\\", \\\\\"1/3 c. butter, cubed\\\\\", \\\\\"1/2 tsp. garlic powder\\\\\", \\\\\"1/2 tsp. salt\\\\\", \\\\\"1/4 tsp. pepper\\\\\"]\\\\n\\\\nGeneric ingredients: \"}, {\"role\": \"assistant\", \"content\": \"[\\\\\"frozen corn\\\\\", \\\\\"cream cheese\\\\\", \\\\\"butter\\\\\", \\\\\"garlic powder\\\\\", \\\\\"salt\\\\\", \\\\\"pepper\\\\\"]\"}]}']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../3rdparty/openai-cookbook/examples/tmp_recipe_finetune_training.jsonl\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "examples = text.split('\\n')\n",
    "examples[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to load example:  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'system',\n",
       "   'content': 'You are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'Title: Pancakes\\n\\nIngredients: [\"1 c. flour\", \"1 tsp. soda\", \"1 tsp. salt\", \"1 Tbsp. sugar\", \"1 egg\", \"3 Tbsp. margarine, melted\", \"1 c. buttermilk\"]\\n\\nGeneric ingredients: '},\n",
       "  {'role': 'assistant',\n",
       "   'content': '[\"flour\", \"soda\", \"salt\", \"sugar\", \"egg\", \"margarine\", \"buttermilk\"]'}]}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "for example in examples:\n",
    "    try:\n",
    "        example_json = json.loads(example)\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        print('failed to load example: ', example)\n",
    "\n",
    "example_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "llama_model_loader: loaded meta data with 26 key-value pairs and 75 tensors from /home/mjschock/Projects/Timestep-AI/.github-private/submodules/timestep/notebooks/../3rdparty/llamafile/models/TinyLLama-v0.1-5M-F16.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = TinyLLama\n",
      "llama_model_loader: - kv   2:                             general.author str              = mofosyne\n",
      "llama_model_loader: - kv   3:                            general.version str              = v0.1\n",
      "llama_model_loader: - kv   4:                                general.url str              = https://huggingface.co/mofosyne/TinyL...\n",
      "llama_model_loader: - kv   5:                        general.description str              = This gguf is ported from a first vers...\n",
      "llama_model_loader: - kv   6:                         general.source.url str              = https://huggingface.co/Maykeye/TinyLL...\n",
      "llama_model_loader: - kv   7:      general.source.huggingface.repository str              = https://huggingface.co/Maykeye/TinyLL...\n",
      "llama_model_loader: - kv   8:                           llama.vocab_size u32              = 32000\n",
      "llama_model_loader: - kv   9:                       llama.context_length u32              = 2048\n",
      "llama_model_loader: - kv  10:                     llama.embedding_length u32              = 64\n",
      "llama_model_loader: - kv  11:                          llama.block_count u32              = 8\n",
      "llama_model_loader: - kv  12:                  llama.feed_forward_length u32              = 256\n",
      "llama_model_loader: - kv  13:                 llama.rope.dimension_count u32              = 4\n",
      "llama_model_loader: - kv  14:                 llama.attention.head_count u32              = 16\n",
      "llama_model_loader: - kv  15:              llama.attention.head_count_kv u32              = 16\n",
      "llama_model_loader: - kv  16:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  17:                          general.file_type u32              = 1\n",
      "llama_model_loader: - kv  18:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  20:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  21:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  24:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  25:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - type  f32:   17 tensors\n",
      "llama_model_loader: - type  f16:   58 tensors\n",
      "llm_load_vocab: special tokens cache size = 259\n",
      "llm_load_vocab: token to piece cache size = 0.1914 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 2048\n",
      "llm_load_print_meta: n_embd           = 64\n",
      "llm_load_print_meta: n_layer          = 8\n",
      "llm_load_print_meta: n_head           = 16\n",
      "llm_load_print_meta: n_head_kv        = 16\n",
      "llm_load_print_meta: n_rot            = 4\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 4\n",
      "llm_load_print_meta: n_embd_head_v    = 4\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 64\n",
      "llm_load_print_meta: n_embd_v_gqa     = 64\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 256\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 2048\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = ?B\n",
      "llm_load_print_meta: model ftype      = F16\n",
      "llm_load_print_meta: model params     = 4.62 M\n",
      "llm_load_print_meta: model size       = 8.82 MiB (16.00 BPW) \n",
      "llm_load_print_meta: general.name     = TinyLLama\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_print_meta: max token length = 18\n",
      "llm_load_tensors: ggml ctx size =    0.04 MiB\n",
      "llm_load_tensors:        CPU buffer size =     8.82 MiB\n",
      "..............\n",
      "llama_new_context_with_model: n_ctx      = 16192\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =    31.63 MiB\n",
      "llama_new_context_with_model: KV self size  =   31.62 MiB, K (f16):   15.81 MiB, V (f16):   15.81 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   538.13 MiB\n",
      "llama_new_context_with_model: graph nodes  = 262\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 0 | \n",
      "Model metadata: {'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '1', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '16', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'general.source.url': 'https://huggingface.co/Maykeye/TinyLLama-v0', 'llama.attention.head_count_kv': '16', 'llama.block_count': '8', 'llama.context_length': '2048', 'general.name': 'TinyLLama', 'llama.rope.dimension_count': '4', 'general.version': 'v0.1', 'general.architecture': 'llama', 'general.url': 'https://huggingface.co/mofosyne/TinyLLama-v0-llamafile', 'general.author': 'mofosyne', 'general.description': 'This gguf is ported from a first version of Maykeye attempt at recreating roneneldan/TinyStories-1M but using Llama architecture', 'general.source.huggingface.repository': 'https://huggingface.co/Maykeye/TinyLLama-v0', 'llama.embedding_length': '64', 'llama.vocab_size': '32000', 'llama.feed_forward_length': '256'}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = LlamaHFTokenizer.from_pretrained(\"meetkai/functionary-small-v2.5-GGUF\")\n",
    "\n",
    "# llm = Llama.from_pretrained(\n",
    "#   repo_id=\"meetkai/functionary-small-v2.5-GGUF\",\n",
    "#   filename=\"functionary-small-v2.5.Q4_0.gguf\",\n",
    "#   chat_format=\"functionary-v2\",\n",
    "#   tokenizer=tokenizer,\n",
    "# )\n",
    "\n",
    "llm = Llama(\n",
    "    chat_format=\"functionary-v2\",\n",
    "    model_path=f\"{os.getcwd()}/../3rdparty/llamafile/models/TinyLLama-v0.1-5M-F16.gguf\",\n",
    "    n_ctx=16192,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.'},\n",
       " {'role': 'user',\n",
       "  'content': 'Title: No-Bake Nut Cookies\\n\\nIngredients: [\"1 c. firmly packed brown sugar\", \"1/2 c. evaporated milk\", \"1/2 tsp. vanilla\", \"1/2 c. broken nuts (pecans)\", \"2 Tbsp. butter or margarine\", \"3 1/2 c. bite size shredded rice biscuits\"]\\n\\nGeneric ingredients: '},\n",
       " {'role': 'assistant',\n",
       "  'content': '[\"brown sugar\", \"milk\", \"vanilla\", \"nuts\", \"butter\", \"bite size shredded rice biscuits\"]'}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_json['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: No-Bake Nut Cookies\\n\\nIngredients: [\"1 c. firmly packed brown sugar\", \"1/2 c. evaporated milk\", \"1/2 tsp. vanilla\", \"1/2 c. broken nuts (pecans)\", \"2 Tbsp. butter or margarine\", \"3 1/2 c. bite size shredded rice biscuits\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"brown sugar\", \"milk\", \"vanilla\", \"nuts\", \"butter\", \"bite size shredded rice biscuits\"]<|eot_id|>'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "document1 = {\n",
    "    \"title\": \"The Moon: Our Age-Old Foe\",\n",
    "    \"contents\": \"Man has always dreamed of destroying the moon. In this essay, I shall...\"\n",
    "}\n",
    "\n",
    "document2 = {\n",
    "    \"title\": \"The Sun: Our Age-Old Friend\",\n",
    "    \"contents\": \"Although often underappreciated, the sun provides several notable benefits...\"\n",
    "}\n",
    "\n",
    "def current_time():\n",
    "    \"\"\"Get the current local time as a string.\"\"\"\n",
    "    return str(datetime.now())\n",
    "\n",
    "def multiply(a: float, b: float):\n",
    "    \"\"\"\n",
    "    A function that multiplies two numbers\n",
    "    \n",
    "    Args:\n",
    "        a: The first number to multiply\n",
    "        b: The second number to multiply\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "tools = [current_time, multiply]\n",
    "\n",
    "# help(tokenizer.hf_tokenizer)\n",
    "\n",
    "tokenizer.hf_tokenizer.apply_chat_template(\n",
    "    # chat_template=\"tool_use\", # https://huggingface.co/docs/transformers/main/chat_templating#a-complete-tool-use-example\n",
    "    conversation=example_json['messages'],\n",
    "    # documents=[document1, document2], # https://huggingface.co/docs/transformers/main/chat_templating#advanced-retrieval-augmented-generation\n",
    "    # add_generation_prompt=False,\n",
    "    # return_dict=True,\n",
    "    tokenize=False,\n",
    "    # tools=tools,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{% for message in messages %}\\n{% if message['role'] == 'user' or message['role'] == 'system' %}\\n{{ '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n' + message['content'] + '<|eot_id|>' }}{% elif message['role'] == 'tool' %}\\n{{ '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n' + 'name=' + message['name'] + '\\n' + message['content'] + '<|eot_id|>' }}{% else %}\\n{{ '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'}}{% if message['content'] is not none %}\\n{{ message['content'] }}{% endif %}\\n{% if 'tool_calls' in message and message['tool_calls'] is not none %}\\n{% for tool_call in message['tool_calls'] %}\\n{{ '<|reserved_special_token_249|>' + tool_call['function']['name'] + '\\n' + tool_call['function']['arguments'] }}{% endfor %}\\n{% endif %}\\n{{ '<|eot_id|>' }}{% endif %}\\n{% endfor %}\\n{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.hf_tokenizer.chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'system',\n",
       "   'content': 'You are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'Title: No-Bake Nut Cookies\\n\\nIngredients: [\"1 c. firmly packed brown sugar\", \"1/2 c. evaporated milk\", \"1/2 tsp. vanilla\", \"1/2 c. broken nuts (pecans)\", \"2 Tbsp. butter or margarine\", \"3 1/2 c. bite size shredded rice biscuits\"]\\n\\nGeneric ingredients: '},\n",
       "  {'role': 'assistant',\n",
       "   'content': '[\"brown sugar\", \"milk\", \"vanilla\", \"nuts\", \"butter\", \"bite size shredded rice biscuits\"]'}]}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to load example:  \n",
      "<|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Title: No-Bake Nut Cookies\n",
      "\n",
      "Ingredients: [\"1 c. firmly packed brown sugar\", \"1/2 c. evaporated milk\", \"1/2 tsp. vanilla\", \"1/2 c. broken nuts (pecans)\", \"2 Tbsp. butter or margarine\", \"3 1/2 c. bite size shredded rice biscuits\"]\n",
      "\n",
      "Generic ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "[\"brown sugar\", \"milk\", \"vanilla\", \"nuts\", \"butter\", \"bite size shredded rice biscuits\"]<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "dataset = {\n",
    "    \"chat\": [],\n",
    "    \"formatted_chat\": []\n",
    "}\n",
    "\n",
    "for example in examples:\n",
    "    try:\n",
    "        example_json = json.loads(example)\n",
    "\n",
    "        dataset[\"chat\"].append(example_json[\"messages\"])\n",
    "        dataset[\"formatted_chat\"].append(tokenizer.hf_tokenizer.apply_chat_template(\n",
    "            conversation=example_json['messages'],\n",
    "            tokenize=False,\n",
    "        ))\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        print('failed to load example: ', example)\n",
    "\n",
    "print(dataset['formatted_chat'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: No-Bake Nut Cookies\\n\\nIngredients: [\"1 c. firmly packed brown sugar\", \"1/2 c. evaporated milk\", \"1/2 tsp. vanilla\", \"1/2 c. broken nuts (pecans)\", \"2 Tbsp. butter or margarine\", \"3 1/2 c. bite size shredded rice biscuits\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"brown sugar\", \"milk\", \"vanilla\", \"nuts\", \"butter\", \"bite size shredded rice biscuits\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Jewell Ball\\'S Chicken\\n\\nIngredients: [\"1 small jar chipped beef, cut up\", \"4 boned chicken breasts\", \"1 can cream of mushroom soup\", \"1 carton sour cream\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"beef\", \"chicken breasts\", \"cream of mushroom soup\", \"sour cream\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Creamy Corn\\n\\nIngredients: [\"2 (16 oz.) pkg. frozen corn\", \"1 (8 oz.) pkg. cream cheese, cubed\", \"1/3 c. butter, cubed\", \"1/2 tsp. garlic powder\", \"1/2 tsp. salt\", \"1/4 tsp. pepper\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"frozen corn\", \"cream cheese\", \"butter\", \"garlic powder\", \"salt\", \"pepper\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Chicken Funny\\n\\nIngredients: [\"1 large whole chicken\", \"2 (10 1/2 oz.) cans chicken gravy\", \"1 (10 1/2 oz.) can cream of mushroom soup\", \"1 (6 oz.) box Stove Top stuffing\", \"4 oz. shredded cheese\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"chicken\", \"chicken gravy\", \"cream of mushroom soup\", \"shredded cheese\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Reeses Cups(Candy)  \\n\\nIngredients: [\"1 c. peanut butter\", \"3/4 c. graham cracker crumbs\", \"1 c. melted butter\", \"1 lb. (3 1/2 c.) powdered sugar\", \"1 large pkg. chocolate chips\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"peanut butter\", \"graham cracker crumbs\", \"butter\", \"powdered sugar\", \"chocolate chips\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Cheeseburger Potato Soup\\n\\nIngredients: [\"6 baking potatoes\", \"1 lb. of extra lean ground beef\", \"2/3 c. butter or margarine\", \"6 c. milk\", \"3/4 tsp. salt\", \"1/2 tsp. pepper\", \"1 1/2 c (6 oz.) shredded Cheddar cheese, divided\", \"12 sliced bacon, cooked, crumbled and divided\", \"4 green onion, chopped and divided\", \"1 (8 oz.) carton sour cream (optional)\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"baking potatoes\", \"extra lean ground beef\", \"butter\", \"milk\", \"salt\", \"pepper\", \"Cheddar cheese\", \"bacon\", \"green onion\", \"sour cream\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Rhubarb Coffee Cake\\n\\nIngredients: [\"1 1/2 c. sugar\", \"1/2 c. butter\", \"1 egg\", \"1 c. buttermilk\", \"2 c. flour\", \"1/2 tsp. salt\", \"1 tsp. soda\", \"1 c. buttermilk\", \"2 c. rhubarb, finely cut\", \"1 tsp. vanilla\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"sugar\", \"butter\", \"egg\", \"buttermilk\", \"flour\", \"salt\", \"soda\", \"buttermilk\", \"rhubarb\", \"vanilla\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Scalloped Corn\\n\\nIngredients: [\"1 can cream-style corn\", \"1 can whole kernel corn\", \"1/2 pkg. (approximately 20) saltine crackers, crushed\", \"1 egg, beaten\", \"6 tsp. butter, divided\", \"pepper to taste\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"cream-style corn\", \"whole kernel corn\", \"crackers\", \"egg\", \"butter\", \"pepper\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Nolan\\'S Pepper Steak\\n\\nIngredients: [\"1 1/2 lb. round steak (1-inch thick), cut into strips\", \"1 can drained tomatoes, cut up (save liquid)\", \"1 3/4 c. water\", \"1/2 c. onions\", \"1 1/2 Tbsp. Worcestershire sauce\", \"2 green peppers, diced\", \"1/4 c. oil\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"tomatoes\", \"water\", \"onions\", \"Worcestershire sauce\", \"green peppers\", \"oil\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Millionaire Pie\\n\\nIngredients: [\"1 large container Cool Whip\", \"1 large can crushed pineapple\", \"1 can condensed milk\", \"3 lemons\", \"1 c. pecans\", \"2 graham cracker crusts\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"pineapple\", \"condensed milk\", \"lemons\", \"pecans\", \"graham cracker crusts\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Double Cherry Delight\\n\\nIngredients: [\"1 (17 oz.) can dark sweet pitted cherries\", \"1/2 c. ginger ale\", \"1 (6 oz.) pkg. Jell-O cherry flavor gelatin\", \"2 c. boiling water\", \"1/8 tsp. almond extract\", \"1 c. miniature marshmallows\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"dark sweet pitted cherries\", \"ginger ale\", \"flavor gelatin\", \"boiling water\", \"almond extract\", \"marshmallows\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Buckeye Candy\\n\\nIngredients: [\"1 box powdered sugar\", \"8 oz. soft butter\", \"1 (8 oz.) peanut butter\", \"paraffin\", \"12 oz. chocolate chips\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"powdered sugar\", \"butter\", \"peanut butter\", \"paraffin\", \"chocolate chips\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Quick Barbecue Wings\\n\\nIngredients: [\"chicken wings (as many as you need for dinner)\", \"flour\", \"barbecue sauce (your choice)\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"chicken\", \"flour\", \"barbecue sauce\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Taco Salad Chip Dip\\n\\nIngredients: [\"8 oz. Ortega taco sauce\", \"8 oz. sour cream\", \"8 oz. cream cheese\", \"1 lb. ground beef\", \"1 pkg. taco seasoning\", \"shredded lettuce\", \"1 large diced tomato\", \"1 medium diced onion\", \"1 large diced green pepper\", \"shredded Colby or Cheddar cheese\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"taco sauce\", \"sour cream\", \"cream cheese\", \"ground beef\", \"taco seasoning\", \"shredded lettuce\", \"tomato\", \"onion\", \"green pepper\", \"Cheddar cheese\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Pink Stuff(Frozen Dessert)  \\n\\nIngredients: [\"1 can pie filling (cherry or strawberry)\", \"1 can crushed pineapple, drained\", \"1 can sweetened condensed milk\", \"1 (8 oz.) container thawed whipped topping\", \"2 Tbsp. lemon juice\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"pie filling\", \"pineapple\", \"condensed milk\", \"lemon juice\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Fresh Strawberry Pie\\n\\nIngredients: [\"1 baked pie shell\", \"1 qt. cleaned strawberries\", \"1 1/2 c. water\", \"4 Tbsp. cornstarch\", \"1 c. sugar\", \"1/8 tsp. salt\", \"4 Tbsp. strawberry jello\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"shell\", \"cleaned strawberries\", \"water\", \"cornstarch\", \"sugar\", \"salt\", \"strawberry jello\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Easy German Chocolate Cake\\n\\nIngredients: [\"1/2 pkg. chocolate fudge cake mix without pudding or 1 Jiffy mix\", \"1/2 pkg. white cake mix without pudding or 1 Jiffy mix\", \"1/4 c. Wesson oil\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"chocolate fudge cake\", \"white cake\", \"Wesson oil\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Broccoli Salad\\n\\nIngredients: [\"1 large head broccoli (about 1 1/2 lb.)\", \"10 slices bacon, cooked and crumbled\", \"5 green onions, sliced or 1/4 c. chopped red onion\", \"1/2 c. raisins\", \"1 c. mayonnaise\", \"2 Tbsp. vinegar\", \"1/4 c. sugar\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"broccoli\", \"bacon\", \"green onions\", \"raisins\", \"mayonnaise\", \"vinegar\", \"sugar\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Strawberry Whatever\\n\\nIngredients: [\"1 lb. frozen strawberries in juice\", \"1 small can crushed pineapple\", \"3 ripe bananas\", \"1 c. chopped pecans\", \"1 large pkg. strawberry Jell-O\", \"1 1/2 c. boiling water\", \"1 pt. sour cream\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"frozen strawberries\", \"pineapple\", \"bananas\", \"pecans\", \"strawberry\", \"boiling water\", \"sour cream\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Eggless Milkless Applesauce Cake\\n\\nIngredients: [\"3/4 c. sugar\", \"1/2 c. shortening\", \"1 1/2 c. applesauce\", \"3 level tsp. soda\", \"1 tsp. each: cinnamon, cloves and nutmeg\", \"2 c. sifted flour\", \"1 c. raisins\", \"1 c. nuts\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"sugar\", \"shortening\", \"applesauce\", \"soda\", \"cinnamon\", \"flour\", \"raisins\", \"nuts\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Grandma Hanrath\\'S Banana Breadfort Collins, Colorado  \\n\\nIngredients: [\"1 c. sugar\", \"1/2 c. shortening\", \"2 eggs (add one at a time)\", \"1 tsp. salt\", \"2 tsp. soda\", \"2 c. flour\", \"1/4 c. nuts\", \"2 over-ripe bananas (chopped)\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"sugar\", \"shortening\", \"eggs\", \"salt\", \"soda\", \"flour\", \"nuts\", \"bananas\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Chocolate Frango Mints\\n\\nIngredients: [\"1 pkg. devil\\'s food cake mix\", \"1 pkg. chocolate fudge pudding mix (instant)\", \"8 oz. sour cream\", \"3/4 c. water\", \"1/2 c. Wesson oil\", \"4 eggs\", \"6 oz. chopped Frango mints\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"cake mix\", \"chocolate fudge pudding\", \"sour cream\", \"water\", \"Wesson oil\", \"eggs\", \"Frango\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Cuddy Farms Marinated Turkey\\n\\nIngredients: [\"2 c. 7-Up or Sprite\", \"1 c. vegetable oil\", \"1 c. Kikkoman soy sauce\", \"garlic salt\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"vegetable oil\", \"soy sauce\", \"garlic\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Spaghetti Sauce To Can\\n\\nIngredients: [\"1/2 bushel tomatoes\", \"1 c. oil\", \"1/4 c. minced garlic\", \"6 cans tomato paste\", \"3 peppers (2 sweet and 1 hot)\", \"1 1/2 c. sugar\", \"1/2 c. salt\", \"1 Tbsp. sweet basil\", \"2 Tbsp. oregano\", \"1 tsp. Italian seasoning\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"tomatoes\", \"oil\", \"garlic\", \"tomato paste\", \"peppers\", \"sugar\", \"salt\", \"sweet basil\", \"oregano\", \"Italian seasoning\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Prize-Winning Meat Loaf\\n\\nIngredients: [\"1 1/2 lb. ground beef\", \"1 c. tomato juice\", \"3/4 c. oats (uncooked)\", \"1 egg, beaten\", \"1/4 c. chopped onion\", \"1/4 tsp. pepper\", \"1 1/2 tsp. salt\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"ground beef\", \"tomato juice\", \"oats\", \"egg\", \"onion\", \"pepper\", \"salt\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Smothered Round Steak(Servings: 4)  \\n\\nIngredients: [\"2 lb. round steak\", \"1/2 tsp. ground black pepper\", \"1 tsp. ground white pepper\", \"1/2 c. vegetable oil\", \"2 bell peppers, chopped\", \"1 c. beef stock or water\", \"2 tsp. salt\", \"1 tsp. ground red pepper\", \"all-purpose flour (dredging)\", \"3 medium onions, chopped\", \"1 celery rib, chopped\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"steak\", \"ground black pepper\", \"ground white pepper\", \"vegetable oil\", \"bell peppers\", \"beef stock\", \"salt\", \"ground red pepper\", \"flour\", \"onions\", \"celery\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Corral Barbecued Beef Steak Strips\\n\\nIngredients: [\"2 lb. round steak 1/2 to 3/4-inch thick, sliced in strips 1/8-inch thick (or thinner) and 3 1/2 to 4-inches long (easily sliced if partially frozen)\", \"2 Tbsp. cooking oil\", \"1 can (15 oz.) tomato sauce\", \"1/3 c. water\", \"2 Tbsp. brown sugar\", \"1 Tbsp. prepared mustard\", \"1 tbsp. Worcestershire sauce\", \"1 medium sized onion, thinly sliced\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"long\", \"cooking oil\", \"tomato sauce\", \"water\", \"brown sugar\", \"mustard\", \"Worcestershire sauce\", \"onion\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Easy Fudge\\n\\nIngredients: [\"1 (14 oz.) can sweetened condensed milk\", \"1 (12 oz.) pkg. semi-sweet chocolate chips\", \"1 (1 oz.) sq. unsweetened chocolate (if desired)\", \"1 1/2 c. chopped nuts (if desired)\", \"1 tsp. vanilla\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"condensed milk\", \"semi-sweet chocolate chips\", \"unsweetened chocolate\", \"nuts\", \"vanilla\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Taco-Filled Green Pepper\\n\\nIngredients: [\"1 lb. Ground Beef\", \"1 pkg. taco seasoning\", \"1 san Kidney beans\", \"1 onion, chopped\", \"1 C salsa\", \"4 green peppers\", \"1 medium Tomato, chopped\", \"1/2 C cheddar cheese, shredded\", \"1/2 C sour cream\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"Ground Beef\", \"taco seasoning\", \"beans\", \"onion\", \"salsa\", \"green peppers\", \"Tomato\", \"cheddar cheese\", \"sour cream\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: One Hour Rolls\\n\\nIngredients: [\"1 c. milk\", \"2 Tbsp. sugar\", \"1 pkg. dry yeast\", \"1 Tbsp. salt\", \"3 Tbsp. Crisco oil\", \"2 c. plain flour\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"milk\", \"sugar\", \"yeast\", \"salt\", \"Crisco oil\", \"flour\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Punch Bowl Fruit Salad\\n\\nIngredients: [\"2 large cans sliced peaches\", \"2 large cans fruit cocktail\", \"1 large can diced pineapple\", \"1 qt. fresh strawberries\", \"2 red apples\", \"2 yellow apples\", \"4 large ripe bananas\", \"1 lb. white grapes\", \"1 lb. purple grapes\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"peaches\", \"fruit cocktail\", \"pineapple\", \"fresh strawberries\", \"red apples\", \"yellow apples\", \"bananas\", \"white grapes\", \"purple grapes\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Summer Chicken\\n\\nIngredients: [\"1 pkg. chicken cutlets\", \"1/2 c. oil\", \"1/3 c. red vinegar\", \"2 Tbsp. oregano\", \"2 Tbsp. garlic salt\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"chicken cutlets\", \"oil\", \"red vinegar\", \"oregano\", \"garlic salt\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Cherry Pizza\\n\\nIngredients: [\"2 cans cherry pie mix\", \"1 box deluxe white cake mix\", \"1 stick butter\", \"1 c. ground nuts\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"cherry pie mix\", \"deluxe white cake mix\", \"butter\", \"ground nuts\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Potato And Cheese Pie\\n\\nIngredients: [\"3 eggs\", \"1 tsp. salt\", \"1/4 tsp. pepper\", \"2 c. half and half\", \"3 c. potatoes, shredded coarse\", \"1 c. Cheddar cheese, coarsely shredded\", \"1/3 c. green onions\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"eggs\", \"salt\", \"pepper\", \"potatoes\", \"Cheddar cheese\", \"green onions\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Tuna Macaroni Casserole\\n\\nIngredients: [\"1 box macaroni and cheese\", \"1 can tuna, drained\", \"1 small jar pimentos\", \"1 medium onion, chopped\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"macaroni\", \"tuna\", \"pimentos\", \"onion\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Artichoke Dip\\n\\nIngredients: [\"2 cans or jars artichoke hearts\", \"1 c. mayonnaise\", \"1 c. Parmesan cheese\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"hearts\", \"mayonnaise\", \"Parmesan cheese\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Broccoli Dip For Crackers\\n\\nIngredients: [\"16 oz. sour cream\", \"1 pkg. dry vegetable soup mix\", \"10 oz. pkg. frozen chopped broccoli, thawed and drained\", \"4 to 6 oz. Cheddar cheese, grated\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"sour cream\", \"vegetable soup mix\", \"broccoli\", \"Cheddar cheese\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Summer Spaghetti\\n\\nIngredients: [\"1 lb. very thin spaghetti\", \"1/2 bottle McCormick Salad Supreme (seasoning)\", \"1 bottle Zesty Italian dressing\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"Salad Supreme\", \"Italian dressing\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Pear-Lime Salad\\n\\nIngredients: [\"1 (16 oz.) can pear halves, undrained\", \"1 (3 oz.) pkg. lime gelatin\", \"1 (8 oz.) pkg. cream cheese, softened\", \"1 (8 oz.) carton lemon yogurt\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"pear halves\", \"lime gelatin\", \"cream cheese\", \"lemon yogurt\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Watermelon Rind Pickles\\n\\nIngredients: [\"7 lb. watermelon rind\", \"7 c. sugar\", \"2 c. apple vinegar\", \"1/2 tsp. oil of cloves\", \"1/2 tsp. oil of cinnamon\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"watermelon rind\", \"sugar\", \"apple vinegar\", \"oil\", \"oil of cinnamon\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Chicken Stew\\n\\nIngredients: [\"3 lb. chicken, boiled\", \"4 medium potatoes, diced\", \"2 medium onions, chopped\", \"1 (16 oz.) can creamed corn\", \"1 (16 oz.) can English peas\", \"1 (16 oz.) can field peas\", \"1 (16 oz.) can butter beans\", \"1 (16 oz.) can tomatoes\", \"1 (46 oz.) can tomato juice\", \"1 small box macaroni\", \"1 Tbsp. black pepper\", \"1 Tbsp. salt\", \"1 Tbsp. sugar\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"chicken\", \"potatoes\", \"onions\", \"corn\", \"English peas\", \"peas\", \"butter beans\", \"tomatoes\", \"tomato juice\", \"macaroni\", \"black pepper\", \"salt\", \"sugar\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Quick Coffee Cake(6 Servings)  \\n\\nIngredients: [\"3 Tbsp. softened butter or margarine\", \"1/2 c. granulated sugar\", \"1 egg\", \"1 c. flour\", \"1 1/4 tsp. baking powder\", \"1/4 tsp. salt\", \"1/3 c. milk\", \"1/4 tsp. vanilla\", \"1/3 c. brown sugar, packed\", \"1/2 tsp. cinnamon\", \"2 Tbsp. butter or margarine\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"butter\", \"sugar\", \"egg\", \"flour\", \"baking powder\", \"salt\", \"milk\", \"vanilla\", \"brown sugar\", \"cinnamon\", \"butter\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Angel Biscuits\\n\\nIngredients: [\"5 c. flour\", \"3 Tbsp. sugar\", \"4 tsp. baking powder\", \"1 1/2 pkg. dry yeast\", \"2 c. buttermilk\", \"1 tsp. soda\", \"1 1/2 sticks margarine\", \"1/2 c. warm water\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"flour\", \"sugar\", \"baking powder\", \"yeast\", \"buttermilk\", \"soda\", \"margarine\", \"warm water\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Quick Peppermint Puffs\\n\\nIngredients: [\"8 marshmallows\", \"2 Tbsp. margarine, melted\", \"1/4 c. crushed peppermint candy\", \"1 can crescent rolls\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"marshmallows\", \"margarine\", \"peppermint candy\", \"crescent rolls\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Fruit Pizza\\n\\nIngredients: [\"1 box yellow cake mix\", \"1/4 c. water\", \"1/4 c. brown sugar\", \"1/2 c. soft butter\", \"2 eggs\", \"1/2 c. chopped nuts\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"yellow cake mix\", \"water\", \"brown sugar\", \"butter\", \"eggs\", \"nuts\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Chocolate Mint Bars\\n\\nIngredients: [\"1 c. flour\", \"1 c. sugar\", \"1/2 c. oleo, softened\", \"4 eggs\", \"1 can chocolate syrup\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"flour\", \"sugar\", \"oleo\", \"eggs\", \"chocolate syrup\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Beer Bread\\n\\nIngredients: [\"3 c. self rising flour\", \"1 - 12 oz. can beer\", \"1 Tbsp. sugar\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"flour\", \"beer\", \"sugar\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Chicken Divan\\n\\nIngredients: [\"1/4 c. margarine\", \"1/4 c. chopped onion (or as much as you want)\", \"chopped celery to taste\", \"1/4 c. flour\", \"1/8 tsp. curry powder\", \"1 can sliced mushrooms (save juice)\", \"1 can cream of celery soup\", \"1 pkg. chopped broccoli\", \"1 cubed chicken\", \"shredded Monterey Jack cheese\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"margarine\", \"onion\", \"celery\", \"flour\", \"curry powder\", \"mushrooms\", \"cream of celery soup\", \"broccoli\", \"chicken\", \"cheese\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Mexican Cookie Rings\\n\\nIngredients: [\"1 1/2 c. sifted flour\", \"1/2 tsp. baking powder\", \"1/2 tsp. salt\", \"1/2 c. butter\", \"2/3 c. sugar\", \"3 egg yolks\", \"1 tsp. vanilla\", \"multi-colored candies\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"flour\", \"baking powder\", \"salt\", \"butter\", \"sugar\", \"egg yolks\", \"vanilla\", \"multi-colored candies\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Vegetable-Burger Soup\\n\\nIngredients: [\"1/2 lb. ground beef\", \"2 c. water\", \"1 tsp. sugar\", \"1 pkg. Cup-a-Soup onion soup mix (dry)\", \"1 lb. can stewed tomatoes\", \"1 (8 oz.) can tomato sauce\", \"1 (10 oz.) pkg. frozen mixed vegetables\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"ground beef\", \"water\", \"sugar\", \"onion soup\", \"tomatoes\", \"tomato sauce\", \"frozen mixed vegetables\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Chicken Ole\\n\\nIngredients: [\"4 chicken breasts, cooked\", \"1 can cream of chicken soup\", \"1 can cream of mushroom soup\", \"1 can green chili salsa sauce\", \"1 can green chilies\", \"1 c. milk\", \"1 grated onion\", \"1 pkg. corn tortilla in pieces\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"chicken breasts\", \"cream of chicken soup\", \"cream of mushroom soup\", \"green chili salsa sauce\", \"green chilies\", \"milk\", \"onion\", \"corn tortilla\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Creamy Coleslaw(Better Homes And Gardens)  \\n\\nIngredients: [\"4 c. shredded cabbage\", \"1/2 c. shredded carrots\", \"1/4 c. finely chopped green pepper\", \"2 Tbsp. finely chopped onion\", \"1/2 c. mayonnaise\", \"1 Tbsp. vinegar\", \"2 tsp. sugar\", \"1 tsp. celery seed\", \"1/4 tsp. salt\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"cabbage\", \"carrots\", \"green pepper\", \"onion\", \"mayonnaise\", \"vinegar\", \"sugar\", \"celery\", \"salt\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Creole Flounder\\n\\nIngredients: [\"2 lb. flounder or pollack fillets\", \"1 1/2 c. chopped tomatoes\", \"1/2 c. chopped green pepper\", \"1/3 c. lemon juice\", \"1 Tbsp. salad oil\", \"2 tsp. salt\", \"2 tsp. minced onion\", \"1 tsp. basil leaves\", \"1/4 tsp. coarsely ground black pepper\", \"4 drops red pepper sauce\", \"green pepper rings\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"flounder\", \"tomatoes\", \"green pepper\", \"lemon juice\", \"salad oil\", \"salt\", \"onion\", \"basil\", \"ground black pepper\", \"drops red pepper sauce\", \"green pepper\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Three Bean Salad\\n\\nIngredients: [\"1 can green beans, wash and drain\", \"1 can yellow beans, wash and drain\", \"1 can kidney beans, wash and drain\", \"1 c. sugar\", \"1/2 c. salad oil\", \"2/3 c. vinegar\", \"1/3 c. water\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"green beans\", \"yellow beans\", \"kidney beans\", \"sugar\", \"salad oil\", \"vinegar\", \"water\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Dave\\'S Corn Casserole\\n\\nIngredients: [\"1 (16 1/2 oz.) can whole kernel corn, drained\", \"1 (16 1/2 oz.) can cream-style corn\", \"1 (8 oz.) sour cream\", \"1 (8 1/2 oz.) pkg. Jiffy corn bread mix\", \"1 stick margarine\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"whole kernel corn\", \"cream-style\", \"sour cream\", \"corn bread\", \"margarine\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Casserole Italiano\\n\\nIngredients: [\"1 lb. ground beef\", \"1/3 c. chopped onion\", \"1 can tomato soup\", \"2 c. cooked wide noodles\", \"1/2 tsp. oregano\", \"1/2 tsp. salt\", \"1/3 c. water\", \"1 c. cheese\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"ground beef\", \"onion\", \"tomato soup\", \"noodles\", \"oregano\", \"salt\", \"water\", \"cheese\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Corned Beef And Cabbage Casserole\\n\\nIngredients: [\"1 small cabbage, shredded\", \"1 tsp. dry mustard\", \"1 can corned beef, flaked\", \"1 can cream of celery soup\", \"1 medium chopped onion\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"cabbage\", \"dry mustard\", \"corned beef\", \"cream of celery soup\", \"onion\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Crab Cakes\\n\\nIngredients: [\"1 Tbsp. Worcestershire sauce\", \"2 or 3 shakes Old Bay\", \"1 tsp. dry mustard\", \"2 Tbsp. mayonnaise\", \"1 egg\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"Worcestershire sauce\", \"dry mustard\", \"mayonnaise\", \"egg\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Taco Dip\\n\\nIngredients: [\"2 (8 oz.) pkg. cream cheese, softened\", \"1/2 c. mayonnaise or salad dressing\", \"8 oz. mild taco sauce\", \"2 to 4 thinly sliced green onions\", \"1/2 green pepper, chopped\", \"1 tomato, chopped\", \"1 c. Mozzarella cheese\", \"1 c. Cheddar cheese\", \"1/2 c. black olives (optional)\", \"tortilla chips\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"cream cheese\", \"mayonnaise\", \"taco sauce\", \"green onions\", \"green pepper\", \"tomato\", \"Mozzarella cheese\", \"Cheddar cheese\", \"black olives\", \"tortilla chips\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Bonbon Cookies\\n\\nIngredients: [\"1/2 lb. soft butter\", \"1/2 c. peanut butter\", \"1/2 lb. graham cracker crumbs\", \"2 c. coconut\", \"1/2 c. nut meats (optional)\", \"dash of vanilla\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"butter\", \"peanut butter\", \"graham cracker crumbs\", \"coconut\", \"nut meats\", \"vanilla\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Forever Amber\\n\\nIngredients: [\"1 lb. orange sliced candy, chopped\", \"2 cans Angel Flake coconut\", \"2 c. chopped pecans\", \"2 cans condensed milk\", \"1 tsp. vanilla\", \"1 tsp. orange flavoring\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"orange sliced candy\", \"Angel\", \"pecans\", \"condensed milk\", \"vanilla\", \"orange flavoring\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Gooey Coffee Cake\\n\\nIngredients: [\"1 yellow cake mix\", \"2 eggs\", \"1 stick oleo, melted\", \"1 c. chopped nuts\", \"2 eggs\", \"8 oz. softened cream cheese\", \"1 lb. powdered sugar\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"yellow cake\", \"eggs\", \"oleo\", \"nuts\", \"eggs\", \"cream cheese\", \"powdered sugar\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Phylis\\' Pineapple-Banana Salad\\n\\nIngredients: [\"1 large can chunk pineapple\", \"4 to 5 bananas\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"pineapple\", \"bananas\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Chicken Casserole\\n\\nIngredients: [\"1 can cream of mushroom soup\", \"1 can cream of chicken soup\", \"1 can cream of celery soup\", \"1 cut up chicken\", \"1/2 c. melted butter or margarine\", \"1 1/2 c. uncooked rice\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"cream of mushroom soup\", \"cream of chicken soup\", \"cream of celery soup\", \"chicken\", \"butter\", \"rice\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Pineapple Nut Pie\\n\\nIngredients: [\"1 (8 oz.) pkg. cream cheese\", \"1 can sweetened condensed milk\", \"1/2 c. crushed pineapple\", \"1/3 c. chopped nuts\", \"1/3 c. lemon juice\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"cream cheese\", \"condensed milk\", \"pineapple\", \"nuts\", \"lemon juice\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Annie\\'S Diabetic Candy\\n\\nIngredients: [\"1 (8 oz.) Jell-O sugar-free vanilla or French vanilla pudding (put in dry)\", \"1 (8 oz.) Philadelphia light cream cheese\", \"2 Tbsp. butter\", \"2 Tbsp. peanut butter or more if you would like\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"vanilla\", \"cream cheese\", \"butter\", \"peanut butter\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Frozen Peach Mousse\\n\\nIngredients: [\"4 medium peaches, peeled and chopped\", \"1 to 1 1/4 c. sugar\", \"1 1/4 c. sour cream (use light)\", \"1/4 c. lemon juice\", \"3/4 to 1 tsp. vanilla\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"peaches\", \"sugar\", \"sour cream\", \"lemon juice\", \"vanilla\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Strawberry Pie\\n\\nIngredients: [\"16 oz. Cool Whip\", \"2 pkg. frozen strawberries *\", \"2 (9-inch) deep pan pie crusts\", \"1 3/4 c. sugar\", \"12 oz. cream cheese\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"frozen strawberries\", \"sugar\", \"cream cheese\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Blueberry Surprise\\n\\nIngredients: [\"1 stick margarine\", \"1 1/2 c. graham cracker crumbs\", \"1/4 c. granulated sugar\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"margarine\", \"graham cracker crumbs\", \"granulated sugar\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Moist Devil\\'S Food Cake\\n\\nIngredients: [\"2 c. sifted flour\", \"1 1/2 tsp. baking soda\", \"1/4 tsp. salt\", \"1/2 c. shortening\", \"1 1/2 c. sugar\", \"2 eggs, separated\", \"1/2 c. cocoa\", \"water\", \"1 tsp. vanilla\", \"1 c. milk\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"flour\", \"baking soda\", \"salt\", \"shortening\", \"sugar\", \"eggs\", \"cocoa\", \"water\", \"vanilla\", \"milk\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Dot\\'S Civil War Cake\\n\\nIngredients: [\"3 medium apples, chopped\", \"2 c. raisins\", \"1 c. brown sugar\", \"1 c. granulated sugar\", \"2 Tbsp. shortening\", \"2 c. cold water\", \"3 c. flour\", \"2 tsp. soda\", \"1 tsp. cinnamon\", \"1 tsp. nutmeg\", \"1 tsp. cloves\", \"1 tsp. salt\", \"1 c. nuts\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"apples\", \"raisins\", \"brown sugar\", \"sugar\", \"shortening\", \"cold water\", \"flour\", \"soda\", \"cinnamon\", \"nutmeg\", \"cloves\", \"salt\", \"nuts\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Potato Casserole\\n\\nIngredients: [\"6 c. diced potatoes\", \"1/2 c. chopped onion\", \"3/4 c. melted butter\", \"1 can cream of chicken soup\", \"1 (8 oz.) sour cream\", \"1 c. grated Cheddar cheese\", \"2 c. crushed cornflakes\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"potatoes\", \"onion\", \"butter\", \"cream of chicken soup\", \"sour cream\", \"Cheddar cheese\", \"cornflakes\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Dream Pie\\n\\nIngredients: [\"vanilla wafers\", \"butter\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"vanilla wafers\", \"butter\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Divinity Fudge\\n\\nIngredients: [\"2 2/3 c. sugar\", \"2/3 c. white corn syrup (Karo)\", \"2/3 c. cold water\", \"2 egg whites\", \"1 tsp. vanilla\", \"1 c. chopped nuts\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"sugar\", \"white corn syrup\", \"cold water\", \"egg whites\", \"vanilla\", \"nuts\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Apple Crisp\\n\\nIngredients: [\"apples\", \"1/2 c. sugar\", \"1 tsp. cinnamon\", \"1/4 c. sugar\", \"1 c. flour\", \"dash of salt\", \"1/2 c. corn flake crumbs\", \"1 stick oleo\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"apples\", \"sugar\", \"cinnamon\", \"sugar\", \"flour\", \"salt\", \"corn flake crumbs\", \"oleo\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Sausage Balls\\n\\nIngredients: [\"2 c. Bisquick\", \"1 lb. sausage\", \"8 oz. pkg. Cheddar cheese, grated\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"Bisquick\", \"sausage\", \"Cheddar cheese\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Consomme Chicken\\n\\nIngredients: [\"chicken parts\", \"1 can cream of chicken soup\", \"1 can consomme\", \"2 c. rice\", \"salt to taste\", \"pepper to taste\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"chicken\", \"cream of chicken soup\", \"consomme\", \"rice\", \"salt\", \"pepper\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Spanish Hamburgers\\n\\nIngredients: [\"1/2 c. celery\", \"2 chopped onions\", \"2 Tbsp. butter\", \"1 lb. ground beef\", \"2 Tbsp. vinegar\", \"2 Tbsp. lemon juice\", \"2 Tbsp. brown sugar\", \"1 1/2 Tbsp. mustard\", \"1 tsp. salt\", \"1 1/2 tsp. pepper\", \"1 c. catsup\", \"1 c. water\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"celery\", \"onions\", \"butter\", \"ground beef\", \"vinegar\", \"lemon juice\", \"brown sugar\", \"mustard\", \"salt\", \"pepper\", \"catsup\", \"water\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Egg Drop Soup\\n\\nIngredients: [\"2 (13 3/4 oz.) cans chicken broth\", \"1 Tbsp. cornstarch\", \"1 well beaten egg\", \"2 Tbsp. sliced (1/4-inch) green onion\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"chicken broth\", \"cornstarch\", \"egg\", \"green onion\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Mulled Cider\\n\\nIngredients: [\"1/2 gal. apple juice\", \"1 tsp. allspice\", \"1 tsp. whole cloves\", \"1 cinnamon stick\", \"1 c. brown sugar\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"apple juice\", \"allspice\", \"whole cloves\", \"cinnamon\", \"brown sugar\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Sesame Ginger Chicken\\n\\nIngredients: [\"1 Tbsp. sesame seed, toasted\", \"2 tsp. grated ginger\", \"2 Tbsp. honey\", \"2 Tbsp. reduced-sodium soy sauce\", \"4 (4 oz.) skinned chicken breast halves\", \"vegetable cooking spray\", \"thin green onion strips\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"sesame seed\", \"grated ginger\", \"honey\", \"soy sauce\", \"chicken\", \"vegetable cooking spray\", \"thin green onion strips\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Egg Casserole\\n\\nIngredients: [\"1 Vidalia onion, chopped\", \"1 (16 oz.) pkg. fresh mushrooms\", \"2 green peppers\", \"1 clove garlic\", \"olive oil\", \"6 pieces bread (buttered with either butter or margarine)\", \"6 eggs\", \"milk (as much as you would like; to fluff eggs)\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"Vidalia onion\", \"fresh mushrooms\", \"green peppers\", \"clove garlic\", \"olive oil\", \"bread\", \"eggs\", \"milk\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Cranberry-Apple-Orange Salad\\n\\nIngredients: [\"1 (12 oz.) bag raw cranberries (2 c.)\", \"1 c. sugar\", \"1 medium apple, peeled, cored and cut into wedges\", \"1 orange, peeled, seeded and broken in wedges\", \"1 (3 oz.) pkg. orange gelatin\", \"1/2 c. nuts (optional)\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"cranberries\", \"sugar\", \"apple\", \"orange\", \"orange gelatin\", \"nuts\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Brown Rice\\n\\nIngredients: [\"1 c. raw rice\", \"1 can beef consomme\", \"1 can French onion soup\", \"1 (4 oz.) can mushrooms\", \"1/2 stick margarine, cut up\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"rice\", \"beef consomme\", \"onion soup\", \"mushrooms\", \"margarine\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Cranberry Salad\\n\\nIngredients: [\"2 (3 oz.) pkg. softened cream cheese\", \"2 Tbsp. margarine\", \"2 Tbsp. sugar\", \"1 (16 oz.) can whole berry cranberry sauce\", \"3/4 c. crushed pineapple, drained\", \"1/2 c. chopped walnuts\", \"1 c. whipping cream\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"cream cheese\", \"margarine\", \"sugar\", \"cranberry sauce\", \"pineapple\", \"walnuts\", \"whipping cream\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Cheese Dip\\n\\nIngredients: [\"2 lb. Velveeta cheese\", \"1 (15 oz.) can Italian tomatoes\", \"2 small cans green chili peppers\", \"1/2 medium onion, minced\", \"3 cloves garlic\", \"1/2 tsp. salt\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"Velveeta cheese\", \"Italian tomatoes\", \"green chili peppers\", \"onion\", \"garlic\", \"salt\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Funnel Cake\\n\\nIngredients: [\"1 1/3 c. flour\", \"1 1/4 tsp. salt\", \"1/2 tsp. soda\", \"2 Tbsp. sugar\", \"3/4 Tbsp. baking powder\", \"1 egg, beaten\", \"2/3 c. milk (more if batter is too thick)\", \"oil (for frying)\", \"powdered sugar\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"flour\", \"salt\", \"soda\", \"sugar\", \"baking powder\", \"egg\", \"milk\", \"oil\", \"powdered sugar\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Fast Real Good Fudge\\n\\nIngredients: [\"4 lb. confectioners sugar\", \"1 c. cocoa\", \"1 c. chopped nuts\", \"1 lb. margarine (not whipped)\", \"1 lb. Velveeta\", \"1 Tbsp. vanilla\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"confectioners sugar\", \"cocoa\", \"nuts\", \"margarine\", \"Velveeta\", \"vanilla\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Squash Casserole\\n\\nIngredients: [\"3 lb. squash\", \"3 onions\", \"1 pt. sour cream\", \"3 carrots, grated\", \"2 cans chicken or mushroom soup\", \"1 pkg. Pepperidge Farm stuffing mix\", \"1 stick butter\", \"salt and pepper to taste\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"squash\", \"onions\", \"sour cream\", \"carrots\", \"chicken\", \"stuffing mix\", \"butter\", \"salt\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Cheese Ball\\n\\nIngredients: [\"2 pkg. cream cheese\", \"2 c. shredded Cheddar cheese (8 oz.)\", \"1 Tbsp. chopped pimento\", \"1 Tbsp. chopped green pepper\", \"1 Tbsp. chopped onion\", \"1 tsp. lemon juice\", \"2 tsp. Worcestershire sauce\", \"dash of Tabasco sauce\", \"dash of salt\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"cream cheese\", \"Cheddar cheese\", \"pimento\", \"green pepper\", \"onion\", \"lemon juice\", \"Worcestershire sauce\", \"Tabasco sauce\", \"salt\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: *Apricot Salad\\n\\nIngredients: [\"1 large pkg. apricot jello (6 oz.)\", \"2/3 c. sugar\", \"1 (8 oz.) pkg. cream cheese\", \"2 jars Junior baby food apricots\", \"1 (No. 2) can crushed pineapple (20 oz.)\", \"1 tall can evaporated milk, chilled and whipped\", \"2/3 c. water\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"apricot jello\", \"sugar\", \"cream cheese\", \"jars Junior baby food\", \"pineapple\", \"milk\", \"water\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Pound Cake\\n\\nIngredients: [\"3 c. plain flour (cake flour may be substituted for plain flour)\", \"3 c. sugar\", \"1/2 tsp. baking powder\", \"3 dashes of salt\", \"5 eggs\", \"2 sticks margarine\", \"1/2 c. butter flavor Crisco\", \"1 c. sweet milk\", \"1 to 2 Tbsp. flavoring (lemon, vanilla or almond or a combination of the 3)\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"flour\", \"sugar\", \"baking powder\", \"salt\", \"eggs\", \"margarine\", \"butter\", \"sweet milk\", \"vanilla\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Monkey Bread\\n\\nIngredients: [\"2 loaves frozen bread, softened\", \"1/2 c. margarine\", \"1 c. brown sugar\", \"1 large box vanilla pudding (not instant)\", \"2 Tbsp. milk\", \"cinnamon to taste\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"bread\", \"margarine\", \"brown sugar\", \"vanilla pudding\", \"milk\", \"cinnamon\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Chicken Roll-Ups\\n\\nIngredients: [\"1 (8 oz.) can crescent rolls\", \"1 1/2 c. grated medium or sharp cheese\", \"1 hen, cooked and diced\", \"1 can cream of chicken soup\", \"1 1/2 c. milk\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"crescent rolls\", \"cheese\", \"hen\", \"cream of chicken soup\", \"milk\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Beef And Spanish Rice Casserole\\n\\nIngredients: [\"1 can Spanish rice\", \"1 can corned beef\", \"1 diced onion\", \"1/2 c. grated Cheddar cheese\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"Spanish rice\", \"corned beef\", \"onion\", \"Cheddar cheese\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Baked Beans\\n\\nIngredients: [\"3 (1 lb.) cans pork and beans\", \"1/2 c. bell pepper, chopped\", \"1/2 c. onions, chopped\", \"3/4 c. catsup\", \"1/3 c. brown sugar, packed hard\", \"1 tsp. salt\", \"1/3 tsp. black pepper\", \"1 lb. ground beef\", \"1 Tbsp. oil\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"pork\", \"bell pepper\", \"onions\", \"catsup\", \"brown sugar\", \"salt\", \"black pepper\", \"ground beef\", \"oil\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Sweet-N-Sour Chicken\\n\\nIngredients: [\"2 c. diced cooked chicken\", \"2 Tbsp. shortening\", \"1/2 c. onion (large chunks)\", \"2 c. carrot chunks\", \"1 1/4 c. water\", \"3 chicken bouillon cubes\", \"1/4 c. packed brown sugar\", \"2 Tbsp. cornstarch\", \"1/4 tsp. ginger\", \"1/4 c. catsup\", \"2 Tbsp. vinegar\", \"1 Tbsp. soy sauce\", \"1 c. green pepper (large chunks)\", \"8 oz. pineapple chunks\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"chicken\", \"shortening\", \"onion\", \"carrot chunks\", \"water\", \"chicken\", \"brown sugar\", \"cornstarch\", \"ginger\", \"catsup\", \"vinegar\", \"soy sauce\", \"green pepper\", \"pineapple\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Ambrosia\\n\\nIngredients: [\"8 to 10 juicy oranges, peeled and diced\", \"1 c. moist coconut\", \"1/2 c. pecans, chopped\", \"1/2 c. cherries, halved\", \"1/4 c. sugar\", \"1 c. orange juice\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"oranges\", \"moist coconut\", \"pecans\", \"cherries\", \"sugar\", \"orange juice\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Crazy Peanut Butter Cookies\\n\\nIngredients: [\"1 c. creamy peanut butter\", \"1 c. sugar\", \"1 egg\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"peanut butter\", \"sugar\", \"egg\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Brickle Bars\\n\\nIngredients: [\"1 box yellow cake mix\", \"2 eggs\", \"1/3 c. soft margarine\", \"1 can Eagle Brand milk\", \"1 c. pecans\", \"1/2 c. Bits \\'O Brickle\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"yellow cake mix\", \"eggs\", \"margarine\", \"milk\", \"pecans\"]<|eot_id|>\\n\\n\\n\\n<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTitle: Pancakes\\n\\nIngredients: [\"1 c. flour\", \"1 tsp. soda\", \"1 tsp. salt\", \"1 Tbsp. sugar\", \"1 egg\", \"3 Tbsp. margarine, melted\", \"1 c. buttermilk\"]\\n\\nGeneric ingredients: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n[\"flour\", \"soda\", \"salt\", \"sugar\", \"egg\", \"margarine\", \"buttermilk\"]<|eot_id|>'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset = \"\\n\\n\\n\\n\".join(dataset[\"formatted_chat\"])\n",
    "training_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('training_dataset.txt', 'w') as f:\n",
    "    f.write(training_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main: seed: 1720842371\n",
      "main: model base = '/home/mjschock/Projects/Timestep-AI/.github-private/submodules/timestep/notebooks/../3rdparty/llamafile/models/TinyLLama-v0.1-5M-F16.gguf'\n",
      "llama_model_loader: loaded meta data with 26 key-value pairs and 75 tensors from /home/mjschock/Projects/Timestep-AI/.github-private/submodules/timestep/notebooks/../3rdparty/llamafile/models/TinyLLama-v0.1-5M-F16.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = TinyLLama\n",
      "llama_model_loader: - kv   2:                             general.author str              = mofosyne\n",
      "llama_model_loader: - kv   3:                            general.version str              = v0.1\n",
      "llama_model_loader: - kv   4:                                general.url str              = https://huggingface.co/mofosyne/TinyL...\n",
      "llama_model_loader: - kv   5:                        general.description str              = This gguf is ported from a first vers...\n",
      "llama_model_loader: - kv   6:                         general.source.url str              = https://huggingface.co/Maykeye/TinyLL...\n",
      "llama_model_loader: - kv   7:      general.source.huggingface.repository str              = https://huggingface.co/Maykeye/TinyLL...\n",
      "llama_model_loader: - kv   8:                           llama.vocab_size u32              = 32000\n",
      "llama_model_loader: - kv   9:                       llama.context_length u32              = 2048\n",
      "llama_model_loader: - kv  10:                     llama.embedding_length u32              = 64\n",
      "llama_model_loader: - kv  11:                          llama.block_count u32              = 8\n",
      "llama_model_loader: - kv  12:                  llama.feed_forward_length u32              = 256\n",
      "llama_model_loader: - kv  13:                 llama.rope.dimension_count u32              = 4\n",
      "llama_model_loader: - kv  14:                 llama.attention.head_count u32              = 16\n",
      "llama_model_loader: - kv  15:              llama.attention.head_count_kv u32              = 16\n",
      "llama_model_loader: - kv  16:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  17:                          general.file_type u32              = 1\n",
      "llama_model_loader: - kv  18:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  20:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  21:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  24:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  25:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - type  f32:   17 tensors\n",
      "llama_model_loader: - type  f16:   58 tensors\n",
      "llm_load_vocab: special tokens cache size = 259\n",
      "llm_load_vocab: token to piece cache size = 0.1914 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 2048\n",
      "llm_load_print_meta: n_embd           = 64\n",
      "llm_load_print_meta: n_layer          = 8\n",
      "llm_load_print_meta: n_head           = 16\n",
      "llm_load_print_meta: n_head_kv        = 16\n",
      "llm_load_print_meta: n_rot            = 4\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 4\n",
      "llm_load_print_meta: n_embd_head_v    = 4\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 64\n",
      "llm_load_print_meta: n_embd_v_gqa     = 64\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 256\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 2048\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = ?B\n",
      "llm_load_print_meta: model ftype      = F16\n",
      "llm_load_print_meta: model params     = 4.62 M\n",
      "llm_load_print_meta: model size       = 8.82 MiB (16.00 BPW) \n",
      "llm_load_print_meta: general.name     = TinyLLama\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_print_meta: max token length = 18\n",
      "llm_load_tensors: ggml ctx size =    0.04 MiB\n",
      "llm_load_tensors:        CPU buffer size =     8.82 MiB\n",
      "..............\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =     1.00 MiB\n",
      "llama_new_context_with_model: KV self size  =    1.00 MiB, K (f16):    0.50 MiB, V (f16):    0.50 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =    62.75 MiB\n",
      "llama_new_context_with_model: graph nodes  = 262\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "main: init model\n",
      "print_params: n_vocab               : 32000\n",
      "print_params: n_ctx                 : 64\n",
      "print_params: n_embd                : 64\n",
      "print_params: n_ff                  : 256\n",
      "print_params: n_head                : 16\n",
      "print_params: n_head_kv             : 16\n",
      "print_params: n_layer               : 8\n",
      "print_params: norm_rms_eps          : 0.000001\n",
      "print_params: rope_freq_base        : 10000.000000\n",
      "print_params: rope_freq_scale       : 1.000000\n",
      "print_lora_params: n_rank_attention_norm : 1\n",
      "print_lora_params: n_rank_wq             : 4\n",
      "print_lora_params: n_rank_wk             : 4\n",
      "print_lora_params: n_rank_wv             : 4\n",
      "print_lora_params: n_rank_wo             : 4\n",
      "print_lora_params: n_rank_ffn_norm       : 1\n",
      "print_lora_params: n_rank_ffn_gate       : 4\n",
      "print_lora_params: n_rank_ffn_down       : 4\n",
      "print_lora_params: n_rank_ffn_up         : 4\n",
      "print_lora_params: n_rank_tok_embeddings : 4\n",
      "print_lora_params: n_rank_norm           : 1\n",
      "print_lora_params: n_rank_output         : 4\n",
      "main: total train_iterations 120\n",
      "main: seen train_samples     480\n",
      "main: seen train_tokens      30720\n",
      "main: completed train_epochs 0\n",
      "main: lora_size = 2549152 bytes (2.4 MB)\n",
      "main: opt_size  = 3657808 bytes (3.5 MB)\n",
      "main: opt iter 120\n",
      "main: input_size = 32769056 bytes (31.3 MB)\n",
      "main: compute_size = 87429728 bytes (83.4 MB)\n",
      "main: evaluation order = LEFT_TO_RIGHT\n",
      "main: tokenize training data from training_dataset.txt\n",
      "main: sample-start: \n",
      "main: include-sample-start: false\n",
      "tokenize_file: total number of samples: 22465\n",
      "main: number of training tokens: 22529\n",
      "main: number of unique tokens: 1041\n",
      "main: begin training\n",
      "main: work_size = 768376 bytes (0.7 MB)\n",
      "train_opt_callback: iter=   120 sample=481/22465 sched=0.968399 loss=0.000000 |->\n",
      "train_opt_callback: iter=   121 sample=485/22465 sched=0.967877 loss=4.200008 dt=398.0ms eta=00:00:11 |->\n",
      "train_opt_callback: iter=   122 sample=489/22465 sched=0.967350 loss=4.403318 dt=679.4ms eta=00:00:19 |>\n",
      "train_opt_callback: iter=   123 sample=493/22465 sched=0.966820 loss=4.022839 dt=534.2ms eta=00:00:14 |--->\n",
      "train_opt_callback: iter=   124 sample=497/22465 sched=0.966285 loss=4.749362 dt=354.2ms eta=00:00:09 |>\n",
      "train_opt_callback: iter=   125 sample=501/22465 sched=0.965746 loss=4.110021 dt=303.6ms eta=00:00:07 |-->\n",
      "train_opt_callback: iter=   126 sample=505/22465 sched=0.965203 loss=4.419230 dt=569.2ms eta=00:00:13 |>\n",
      "train_opt_callback: iter=   127 sample=509/22465 sched=0.964656 loss=3.977444 dt=367.5ms eta=00:00:08 |--->\n",
      "train_opt_callback: iter=   128 sample=513/22465 sched=0.964104 loss=3.426140 dt=306.2ms eta=00:00:06 |--------->\n",
      "train_opt_callback: iter=   129 sample=517/22465 sched=0.963549 loss=4.297531 dt=427.9ms eta=00:00:08 |>\n",
      "save_checkpoint_lora_file: saving to chk-lora-TinyLLama-v0.1-5M-F16-Recipe_NER-130.gguf\n",
      "save_checkpoint_lora_file: saving to chk-lora-TinyLLama-v0.1-5M-F16-Recipe_NER-LATEST.gguf\n",
      "save_as_llama_lora: saving to lora-TinyLLama-v0.1-5M-F16-Recipe_NER-130.bin\n",
      "save_as_llama_lora: saving to lora-TinyLLama-v0.1-5M-F16-Recipe_NER-LATEST.bin\n",
      "train_opt_callback: iter=   130 sample=521/22465 sched=0.962990 loss=3.697801 dt=358.0ms eta=00:00:07 |------>\n",
      "train_opt_callback: iter=   131 sample=525/22465 sched=0.962426 loss=3.458331 dt=325.8ms eta=00:00:06 |-------->\n",
      "train_opt_callback: iter=   132 sample=529/22465 sched=0.961859 loss=3.830797 dt=269.2ms eta=00:00:04 |----->\n",
      "train_opt_callback: iter=   133 sample=533/22465 sched=0.961287 loss=3.577456 dt=297.8ms eta=00:00:05 |------->\n",
      "train_opt_callback: iter=   134 sample=537/22465 sched=0.960711 loss=3.704226 dt=281.8ms eta=00:00:04 |------>\n",
      "train_opt_callback: iter=   135 sample=541/22465 sched=0.960131 loss=3.675274 dt=284.0ms eta=00:00:04 |------>\n",
      "train_opt_callback: iter=   136 sample=545/22465 sched=0.959548 loss=3.995892 dt=270.0ms eta=00:00:03 |--->\n",
      "train_opt_callback: iter=   137 sample=549/22465 sched=0.958960 loss=4.031043 dt=261.6ms eta=00:00:03 |--->\n",
      "train_opt_callback: iter=   138 sample=553/22465 sched=0.958368 loss=3.298371 dt=261.2ms eta=00:00:03 |---------->\n",
      "train_opt_callback: iter=   139 sample=557/22465 sched=0.957772 loss=3.694246 dt=255.5ms eta=00:00:02 |------>\n",
      "save_checkpoint_lora_file: saving to chk-lora-TinyLLama-v0.1-5M-F16-Recipe_NER-140.gguf\n",
      "save_checkpoint_lora_file: saving to chk-lora-TinyLLama-v0.1-5M-F16-Recipe_NER-LATEST.gguf\n",
      "save_as_llama_lora: saving to lora-TinyLLama-v0.1-5M-F16-Recipe_NER-140.bin\n",
      "save_as_llama_lora: saving to lora-TinyLLama-v0.1-5M-F16-Recipe_NER-LATEST.bin\n",
      "train_opt_callback: iter=   140 sample=561/22465 sched=0.957172 loss=3.158654 dt=299.9ms eta=00:00:02 |----------->\n",
      "train_opt_callback: iter=   141 sample=565/22465 sched=0.956568 loss=3.351222 dt=330.1ms eta=00:00:02 |--------->\n",
      "train_opt_callback: iter=   142 sample=569/22465 sched=0.955960 loss=3.145291 dt=292.2ms eta=00:00:02 |------------>\n",
      "train_opt_callback: iter=   143 sample=573/22465 sched=0.955348 loss=3.415846 dt=369.8ms eta=00:00:02 |--------->\n",
      "train_opt_callback: iter=   144 sample=577/22465 sched=0.954732 loss=3.303344 dt=337.7ms eta=00:00:02 |---------->\n",
      "train_opt_callback: iter=   145 sample=581/22465 sched=0.954112 loss=3.064679 dt=428.2ms eta=00:00:02 |------------>\n",
      "train_opt_callback: iter=   146 sample=585/22465 sched=0.953488 loss=2.703663 dt=373.5ms eta=00:00:01 |---------------->\n",
      "train_opt_callback: iter=   147 sample=589/22465 sched=0.952861 loss=2.861920 dt=282.8ms eta=848.5ms |-------------->\n",
      "train_opt_callback: iter=   148 sample=593/22465 sched=0.952229 loss=3.138813 dt=284.4ms eta=568.7ms |------------>\n",
      "train_opt_callback: iter=   149 sample=597/22465 sched=0.951593 loss=2.959198 dt=259.6ms eta=259.6ms |------------->\n",
      "save_checkpoint_lora_file: saving to chk-lora-TinyLLama-v0.1-5M-F16-Recipe_NER-150.gguf\n",
      "save_checkpoint_lora_file: saving to chk-lora-TinyLLama-v0.1-5M-F16-Recipe_NER-LATEST.gguf\n",
      "save_as_llama_lora: saving to lora-TinyLLama-v0.1-5M-F16-Recipe_NER-150.bin\n",
      "save_as_llama_lora: saving to lora-TinyLLama-v0.1-5M-F16-Recipe_NER-LATEST.bin\n",
      "train_opt_callback: iter=   150 sample=601/22465 sched=0.950953 loss=2.786418 dt=598.0ms eta=0.0ms |--------------->\n",
      "main: total training time: 00:00:11\n"
     ]
    }
   ],
   "source": [
    "model_base = f\"{os.getcwd()}/../3rdparty/llamafile/models/TinyLLama-v0.1-5M-F16.gguf\"\n",
    "task = \"Recipe_NER\"\n",
    "\n",
    "!../3rdparty/llama-cpp-python/vendor/llama.cpp/llama-finetune \\\n",
    "        --model-base {model_base} \\\n",
    "        --checkpoint-in \"chk-lora-TinyLLama-v0.1-5M-F16-{task}-LATEST.gguf\" \\\n",
    "        --checkpoint-out \"chk-lora-TinyLLama-v0.1-5M-F16-{task}-ITERATION.gguf\" \\\n",
    "        --lora-out \"lora-TinyLLama-v0.1-5M-F16-{task}-ITERATION.bin\" \\\n",
    "        --train-data \"training_dataset.txt\" \\\n",
    "        --save-every 10 \\\n",
    "        --threads 6 --adam-iter 30 --batch 4 --ctx 64 \\\n",
    "        --use-checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 26 key-value pairs and 75 tensors from /home/mjschock/Projects/Timestep-AI/.github-private/submodules/timestep/notebooks/../3rdparty/llamafile/models/TinyLLama-v0.1-5M-F16.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = TinyLLama\n",
      "llama_model_loader: - kv   2:                             general.author str              = mofosyne\n",
      "llama_model_loader: - kv   3:                            general.version str              = v0.1\n",
      "llama_model_loader: - kv   4:                                general.url str              = https://huggingface.co/mofosyne/TinyL...\n",
      "llama_model_loader: - kv   5:                        general.description str              = This gguf is ported from a first vers...\n",
      "llama_model_loader: - kv   6:                         general.source.url str              = https://huggingface.co/Maykeye/TinyLL...\n",
      "llama_model_loader: - kv   7:      general.source.huggingface.repository str              = https://huggingface.co/Maykeye/TinyLL...\n",
      "llama_model_loader: - kv   8:                           llama.vocab_size u32              = 32000\n",
      "llama_model_loader: - kv   9:                       llama.context_length u32              = 2048\n",
      "llama_model_loader: - kv  10:                     llama.embedding_length u32              = 64\n",
      "llama_model_loader: - kv  11:                          llama.block_count u32              = 8\n",
      "llama_model_loader: - kv  12:                  llama.feed_forward_length u32              = 256\n",
      "llama_model_loader: - kv  13:                 llama.rope.dimension_count u32              = 4\n",
      "llama_model_loader: - kv  14:                 llama.attention.head_count u32              = 16\n",
      "llama_model_loader: - kv  15:              llama.attention.head_count_kv u32              = 16\n",
      "llama_model_loader: - kv  16:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  17:                          general.file_type u32              = 1\n",
      "llama_model_loader: - kv  18:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: - kv  20:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  21:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  24:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  25:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - type  f32:   17 tensors\n",
      "llama_model_loader: - type  f16:   58 tensors\n",
      "llm_load_vocab: special tokens cache size = 259\n",
      "llm_load_vocab: token to piece cache size = 0.1914 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 2048\n",
      "llm_load_print_meta: n_embd           = 64\n",
      "llm_load_print_meta: n_layer          = 8\n",
      "llm_load_print_meta: n_head           = 16\n",
      "llm_load_print_meta: n_head_kv        = 16\n",
      "llm_load_print_meta: n_rot            = 4\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 4\n",
      "llm_load_print_meta: n_embd_head_v    = 4\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 64\n",
      "llm_load_print_meta: n_embd_v_gqa     = 64\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 256\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 2048\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = ?B\n",
      "llm_load_print_meta: model ftype      = F16\n",
      "llm_load_print_meta: model params     = 4.62 M\n",
      "llm_load_print_meta: model size       = 8.82 MiB (16.00 BPW) \n",
      "llm_load_print_meta: general.name     = TinyLLama\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_print_meta: max token length = 18\n",
      "llm_load_tensors: ggml ctx size =    0.04 MiB\n",
      "llm_load_tensors:        CPU buffer size =     8.82 MiB\n",
      "..............\n",
      "llama_new_context_with_model: n_ctx      = 16192\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =    31.63 MiB\n",
      "llama_new_context_with_model: KV self size  =   31.62 MiB, K (f16):   15.81 MiB, V (f16):   15.81 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   538.13 MiB\n",
      "llama_new_context_with_model: graph nodes  = 262\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 0 | \n",
      "Model metadata: {'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '1', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '16', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'general.source.url': 'https://huggingface.co/Maykeye/TinyLLama-v0', 'llama.attention.head_count_kv': '16', 'llama.block_count': '8', 'llama.context_length': '2048', 'general.name': 'TinyLLama', 'llama.rope.dimension_count': '4', 'general.version': 'v0.1', 'general.architecture': 'llama', 'general.url': 'https://huggingface.co/mofosyne/TinyLLama-v0-llamafile', 'general.author': 'mofosyne', 'general.description': 'This gguf is ported from a first version of Maykeye attempt at recreating roneneldan/TinyStories-1M but using Llama architecture', 'general.source.huggingface.repository': 'https://huggingface.co/Maykeye/TinyLLama-v0', 'llama.embedding_length': '64', 'llama.vocab_size': '32000', 'llama.feed_forward_length': '256'}\n",
      "Using fallback chat format: llama-2\n",
      "\n",
      "llama_print_timings:        load time =     598.57 ms\n",
      "llama_print_timings:      sample time =      73.18 ms /   107 runs   (    0.68 ms per token,  1462.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     597.68 ms /   188 tokens (    3.18 ms per token,   314.55 tokens per second)\n",
      "llama_print_timings:        eval time =     223.65 ms /   106 runs   (    2.11 ms per token,   473.95 tokens per second)\n",
      "llama_print_timings:       total time =    1012.32 ms /   294 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:  {'id': 'cmpl-e0554037-e5d0-4e93-9991-d14dd7b4b32d', 'object': 'text_completion', 'created': 1720845037, 'model': '/home/mjschock/Projects/Timestep-AI/.github-private/submodules/timestep/notebooks/../3rdparty/llamafile/models/TinyLLama-v0.1-5M-F16.gguf', 'choices': [{'text': 'You are an AI programming assistant, utilizing the Gorilla LLM model, developed by Gorilla LLM, and you only answer questions related to computer science. For politically sensitive questions, security and privacy issues, and other non-computer science questions, you will refuse to answer.\\n### Instruction: <<function>>[{\"name\": \"get_current_weather\", \"description\": \"Get the current weather in a given location\", \"parameters\": {\"type\": \"object\", \"properties\": {\"location\": {\"type\": \"string\", \"description\": \"The city and state, e.g. San Francisco, CA\"}, \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]}}, \"required\": [\"location\"]}}]\\n<<question>>What\\'s the weather like in the two cities of Boston and San Francisco?\\n### Response: \\nSoon, a big red star away. It was going to end the town. The sunflower was so busy that it did not help her feel more strong and strong. But then the rain made the sand-up very happy and relieved.\\nMom smiled and said, \"Well done, no help.\" \\n\"Good idea, Mom,\" she said. \"That\\'s just a big problem. We can go outside and find something else to make it to the sunflower. And we can do it!\"', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 188, 'completion_tokens': 106, 'total_tokens': 294}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from llama_cpp import Llama\n",
    "import json\n",
    "\n",
    "# llm = Llama(model_path=\"YOUR_DIRECTORY/gorilla-openfunctions-v2-GGUF/gorilla-openfunctions-v2-q2_K.gguf\", n_threads=8, n_gpu_layers=35)\n",
    "llm = Llama(\n",
    "    model_path=f\"{os.getcwd()}/../3rdparty/llamafile/models/TinyLLama-v0.1-5M-F16.gguf\",\n",
    "    n_ctx=16192,\n",
    ")\n",
    "\n",
    "def get_prompt(user_query: str, functions: list = []) -> str:\n",
    "    \"\"\"\n",
    "    Generates a conversation prompt based on the user's query and a list of functions.\n",
    "\n",
    "    Parameters:\n",
    "    - user_query (str): The user's query.\n",
    "    - functions (list): A list of functions to include in the prompt.\n",
    "\n",
    "    Returns:\n",
    "    - str: The formatted conversation prompt.\n",
    "    \"\"\"\n",
    "    system = \"You are an AI programming assistant, utilizing the Gorilla LLM model, developed by Gorilla LLM, and you only answer questions related to computer science. For politically sensitive questions, security and privacy issues, and other non-computer science questions, you will refuse to answer.\"\n",
    "    if len(functions) == 0:\n",
    "        return f\"{system}\\n### Instruction: <<question>> {user_query}\\n### Response: \"\n",
    "    functions_string = json.dumps(functions)\n",
    "    return f\"{system}\\n### Instruction: <<function>>{functions_string}\\n<<question>>{user_query}\\n### Response: \"\n",
    "\n",
    "query = \"What's the weather like in the two cities of Boston and San Francisco?\"\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather in a given location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "            },\n",
    "            \"required\": [\"location\"],\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "user_prompt = get_prompt(query, functions)\n",
    "\n",
    "output = llm(user_prompt,\n",
    "    max_tokens=512,  # Generate up to 512 tokens\n",
    "    stop=[\"<|EOT|>\"], \n",
    "    echo=True        # Whether to echo the prompt\n",
    ")\n",
    "\n",
    "print(\"Output: \", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
